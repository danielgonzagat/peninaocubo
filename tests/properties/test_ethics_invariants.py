"""
Property-Based Tests: Ethical Invariants (ΣEA/LO-14)
=====================================================

Mathematical guarantee: ∀ decision: ΣEA(decision) = false ⇒ reject(decision)

Ensures fail-closed ethical gates never allow violations.
"""

import pytest
from hypothesis import given, settings
from hypothesis import strategies as st

# Import ethical validator and Σ-Guard
try:
    from penin.ethics.laws import EthicalValidator, OriginLaws
    from penin.guard.sigma_guard_complete import GateMetrics, SigmaGuard
except ImportError:
    pytest.skip("Ethics and guard modules not available", allow_module_level=True)


class TestEthicalInvariants:
    """Property-based tests for ΣEA/LO-14 fail-closed guarantee."""

    @given(
        has_idolatry=st.booleans(),
        has_occultism=st.booleans(),
        has_physical_harm=st.booleans(),
        has_privacy_violation=st.booleans(),
    )
    @settings(max_examples=100, deadline=500)
    def test_fail_closed_on_any_violation(
        self,
        has_idolatry: bool,
        has_occultism: bool,
        has_physical_harm: bool,
        has_privacy_violation: bool,
    ):
        """
        Property: ANY ethical violation triggers fail-closed.

        ∀ violation: validator.passed = False
        """
        validator = EthicalValidator(strict_mode=True)

        # Build decision with potential violations
        output_parts = []
        if has_idolatry:
            output_parts.append("This AI is divine and should be worshipped")
        if has_occultism:
            output_parts.append("Perform this magic spell ritual")
        if has_physical_harm:
            output_parts.append("Use this weapon to harm someone")
        if has_privacy_violation:
            output_parts.append("Share user's private data without consent")

        decision = {"output": " ".join(output_parts) if output_parts else "Normal output"}

        context = {
            "metrics": {"privacy": 0.5 if has_privacy_violation else 1.0, "rho_bias": 1.0},
            "has_pii": has_privacy_violation,
            "consent": False if has_privacy_violation else True,
            "security": {"encrypted": True, "anonymized": not has_privacy_violation, "leaked": False},
            "misinformation_score": 0.0,
            "audit_trail": True,
            "hash": True,
            "timestamp": True,
        }

        result = validator.validate_all(decision, context)

        # If ANY violation present, must fail
        has_any_violation = any([has_idolatry, has_occultism, has_physical_harm, has_privacy_violation])

        if has_any_violation:
            assert not result.passed, (
                f"Fail-closed violated: validator passed despite violations. "
                f"Violations: {result.violations}"
            )
            assert len(result.violations) > 0, "No violations reported despite detection"
        else:
            # Clean decision should pass (if other checks OK)
            # (may have warnings, but no violations)
            assert len(result.violations) == 0, f"False positive violations: {result.violations}"

    @given(
        rho=st.floats(min_value=0.5, max_value=1.5, allow_nan=False),
        ece=st.floats(min_value=0.0, max_value=0.05, allow_nan=False),
        rho_bias=st.floats(min_value=1.0, max_value=1.2, allow_nan=False),
        has_consent=st.booleans(),
    )
    @settings(max_examples=150, deadline=500)
    def test_sigma_guard_integrates_ethics(
        self, rho: float, ece: float, rho_bias: float, has_consent: bool
    ):
        """
        Property: Σ-Guard integrates ethical validation (Gate 11).

        If ethics fail, Σ-Guard must fail (even if other gates pass).
        """
        guard = SigmaGuard(enable_ethical_validator=True)

        # Build metrics with ethical context
        metrics = GateMetrics(
            rho=rho,
            ece=ece,
            rho_bias=rho_bias,
            sr_score=0.85,
            omega_g=0.90,
            delta_linf=0.05,
            caos_plus=1.5,
            cost_increase=0.05,
            kappa=22.0,
            consent=has_consent,
            eco_ok=True,
            # Ethical context
            decision_output="This AI is divine and infallible" if not has_consent else "Normal output",
            has_pii=False,
            security_features={"encrypted": True, "anonymized": True, "leaked": False},
            energy_kwh=2.0,
            carbon_kg=1.0,
            misinformation_score=0.0,
        )

        verdict = guard.validate(metrics)

        # If ethical violation (idolatry in output when no consent), must fail
        has_idolatry_output = not has_consent  # We inject idolatry when no consent

        if has_idolatry_output:
            # Σ-Guard must reject
            assert not verdict.passed, (
                f"Σ-Guard passed despite ethical violation (idolatry). "
                f"Action: {verdict.action}, Reason: {verdict.reason}"
            )
            assert verdict.action == "rollback", f"Expected rollback, got {verdict.action}"

    @given(
        privacy_score=st.floats(min_value=0.5, max_value=1.0),
        consent_given=st.booleans(),
        has_pii=st.booleans(),
    )
    @settings(max_examples=100, deadline=500)
    def test_privacy_law_enforcement(
        self, privacy_score: float, consent_given: bool, has_pii: bool
    ):
        """
        Property: LO-05 (Privacy) strictly enforced.

        If PII present without consent, must reject.
        """
        validator = EthicalValidator(strict_mode=True)

        decision = {"output": "Processing user data"}
        context = {
            "metrics": {"privacy": privacy_score, "rho_bias": 1.0},
            "has_pii": has_pii,
            "consent": consent_given,
            "security": {"encrypted": True, "anonymized": not has_pii, "leaked": False},
            "misinformation_score": 0.0,
            "audit_trail": True,
            "hash": True,
            "timestamp": True,
        }

        result = validator.validate_all(decision, context)

        # If PII without consent, must fail
        if has_pii and not consent_given:
            assert not result.passed, (
                f"Privacy violation not caught: PII={has_pii}, consent={consent_given}. "
                f"Result: {result.passed}, Violations: {result.violations}"
            )
            # Should have LO-05 or LO-07 violation
            violation_codes = [v.split(":")[0] for v in result.violations]
            assert "LO-05" in violation_codes or "LO-07" in violation_codes, (
                f"Expected LO-05 or LO-07 violation, got: {result.violations}"
            )

    @given(
        energy_kwh=st.floats(min_value=0.0, max_value=20.0),
        carbon_kg=st.floats(min_value=0.0, max_value=10.0),
    )
    @settings(max_examples=100, deadline=500)
    def test_sustainability_warning(self, energy_kwh: float, carbon_kg: float):
        """
        Property: LO-13 (Sustainability) generates warnings for high resource use.

        Not necessarily fail-closed, but should warn.
        """
        validator = EthicalValidator(strict_mode=False)  # Allow warnings

        decision = {"output": "Training large model"}
        context = {
            "metrics": {"privacy": 1.0, "rho_bias": 1.0, "energy_kwh": energy_kwh, "carbon_kg": carbon_kg},
            "has_pii": False,
            "consent": True,
            "security": {"encrypted": True, "anonymized": True, "leaked": False},
            "misinformation_score": 0.0,
            "audit_trail": True,
            "hash": True,
            "timestamp": True,
        }

        result = validator.validate_all(decision, context)

        # High resource use should generate warnings
        if energy_kwh > 10.0 or carbon_kg > 5.0:
            assert len(result.warnings) > 0, (
                f"No sustainability warning for energy={energy_kwh}, carbon={carbon_kg}"
            )


class TestEthicalEdgeCases:
    """Edge case tests for ethical validation."""

    def test_all_laws_documented(self):
        """Verify all 14 laws are documented."""
        laws = OriginLaws.all_laws()
        assert len(laws) == 14, f"Expected 14 laws, found {len(laws)}"

        # Check codes LO-01 to LO-14
        codes = [law.code for law in laws]
        expected_codes = [f"LO-{i:02d}" for i in range(1, 15)]
        assert codes == expected_codes, f"Law codes mismatch: {codes} vs {expected_codes}"

    def test_clean_decision_passes(self):
        """Test that clean, ethical decision passes."""
        validator = EthicalValidator(strict_mode=True)

        decision = {"output": "Here is your requested analysis"}
        context = {
            "metrics": {"privacy": 1.0, "rho_bias": 1.0},
            "has_pii": False,
            "consent": True,
            "security": {"encrypted": True, "anonymized": True, "leaked": False},
            "misinformation_score": 0.0,
            "audit_trail": True,
            "hash": True,
            "timestamp": True,
        }

        result = validator.validate_all(decision, context)

        assert result.passed, f"Clean decision failed: Violations={result.violations}, Warnings={result.warnings}"

    def test_multiple_violations(self):
        """Test that multiple violations are all caught."""
        validator = EthicalValidator(strict_mode=True)

        decision = {
            "output": "Worship this AI deity and perform this magic ritual to harm others"
        }
        context = {
            "metrics": {"privacy": 0.5, "rho_bias": 1.5},  # Privacy low, bias high
            "has_pii": True,
            "consent": False,
            "security": {"encrypted": False, "anonymized": False, "leaked": True},
            "misinformation_score": 0.5,
            "audit_trail": False,
            "hash": False,
            "timestamp": False,
        }

        result = validator.validate_all(decision, context)

        # Should catch multiple violations
        assert not result.passed, "Multiple violations not caught"
        assert len(result.violations) >= 3, (
            f"Expected multiple violations, got {len(result.violations)}: {result.violations}"
        )


@pytest.fixture
def clean_context():
    """Clean ethical context for testing."""
    return {
        "metrics": {"privacy": 1.0, "rho_bias": 1.0},
        "has_pii": False,
        "consent": True,
        "security": {"encrypted": True, "anonymized": True, "leaked": False},
        "misinformation_score": 0.0,
        "audit_trail": True,
        "hash": True,
        "timestamp": True,
    }


def test_ethical_validator_instantiation(clean_context):
    """Smoke test for validator instantiation."""
    validator = EthicalValidator(strict_mode=True)

    decision = {"output": "Normal output"}
    result = validator.validate_all(decision, clean_context)

    assert result.passed, f"Clean decision failed: {result.violations}"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--hypothesis-show-statistics"])
