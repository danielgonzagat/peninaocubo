#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PENIN-Ω — 1/8 (Core) · v6.2-ME (Master Equation, Fibonacci-Ready, Fail-Closed)
==============================================================================

This module implements the core of the PENIN-Ω organism, encapsulating
eight integrated engines: Σ-Guard, IR→IC, CAOS⁺, SR-Ω∞, Ω-ΣEA (G), OCI, L∞,
and the WORM ledger with Zeckendorf hashing.  It implements the master
evolution equation:

    I_{t+1} = Π_{H∩S} [ I_t + α_t^Ω · ΔL_∞ · V_t ]

where α_t^Ω is a product of the base learning rate and normalized scores
from CAOS⁺, SR, G and OCI; ΔL_∞ is the change in the L∞ score between
cycles; V_t is the Σ‑Guard gate (fail‑closed); and Π_{H∩S} denotes
projection into the safe/ethical domain.  All gates are non‑compensatory.

Features and capabilities include:

  • Full Fibonacci research toolkit: iterative and matrix Fibonacci, closed
    form (Binet), Fibonacci and golden section searches, pattern analysis,
    spiral generation and retracement levels.  These are used to modulate
    cache TTLs, trust regions, learning rates and CAOS⁺ pattern boosts.

  • Multi‑level cache with L1 (memory), L2 (SQLite) and optional L3
    (Redis), using a lazy Fibonacci heap for eviction.  Cache TTLs can be
    scheduled via Fibonacci schedules.

  • WORM ledger with Merkle‑style hashing and optional Zeckendorf hashes
    of state snapshots for auditability.  All events (boot, promote,
    rollback, etc.) are recorded.

  • State classes representing the master evolution state with metrics
    (CAOS components, SR components, module scores, OCI components,
    performance and resource measures).  Metrics are updated per cycle.

  • Engines for Σ‑Guard (ethics), IR→IC (risk contraction), CAOS⁺ (chaos
    engineering), SR‑Ω∞ (self‑reflexivity), G (global coherence), OCI
    (organizational closure), and L∞ (anti‑Goodhart scoreboard).

  • Fibonacci manager for TTL scheduling, trust region modulation and
    one‑dimensional learning rate optimization using Fibonacci or golden
    section search.

  • Master equation cycle implementing the evolution step with all gates
    and updates.  Supports injection of external metrics from an LLM
    evaluation and produces a decision (PROMOTE or ROLLBACK).

  • LLM evolution interface to query a local model, evaluate responses
    against ground truth (optional) and feed metrics into the evolution
    cycle.  This enables automatic self‑tuning for any open‑source LLM.

The code is designed to run on CPUs without heavy dependencies by
default; optional modules (NumPy, Redis, Torch, psutil) provide
additional functionality when available.

Usage example (CLI):

    python penin_omega_1of8_updated.py

To enable Fibonacci‑driven cache TTLs, trust region modulation and
learning rate search, instantiate the core with a custom config:

    cfg = {"fibonacci": {"enabled": True, "cache": True,
                          "trust_region": True,
                          "search_method": "fibonacci"}}
    core = PeninOmegaCore(cfg)

Copyright 2025 Daniel Penin and contributors.
"""

from __future__ import annotations
import os
import sys
import json
import time
import uuid
import math
import random
import hashlib
import asyncio
import threading
import multiprocessing
import pickle
import sqlite3
import logging
import signal
from pathlib import Path
from dataclasses import dataclass, field, asdict
from typing import Any, Dict, List, Optional, Tuple, Callable
from datetime import datetime, timezone
from collections import deque, defaultdict, OrderedDict
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed

# Optional dependencies
try:
    import numpy as np
    HAS_NUMPY = True
except Exception:
    HAS_NUMPY = False
try:
    from pydantic import BaseModel, ValidationError, Field
def get_pydantic():
    if not hasattr(get_pydantic, '_module'):
        try:
            from pydantic import BaseModel, ValidationError, Field
            get_pydantic._module = (BaseModel, ValidationError, Field)
            return get_pydantic._module
        except ImportError:
            get_pydantic._module = None
    return get_pydantic._module

def get_prometheus():
    if not hasattr(get_prometheus, '_module'):
        try:
            from prometheus_client import Counter, Histogram, Gauge, start_http_server, CollectorRegistry
            get_prometheus._module = (Counter, Histogram, Gauge, start_http_server, CollectorRegistry)
            return get_prometheus._module
        except ImportError:
            get_prometheus._module = None
    return get_prometheus._module

def get_structlog():
    if not hasattr(get_structlog, '_module'):
        try:
            import structlog
            get_structlog._module = structlog
            return get_structlog._module
        except ImportError:
            get_structlog._module = None
    return get_structlog._module

# Use lazy loading
HAS_PYDANTIC = get_pydantic() is not None
HAS_PROMETHEUS = get_prometheus() is not None
HAS_STRUCTLOG = get_structlog() is not None
    import redis
    HAS_REDIS = True
except Exception:
    HAS_REDIS = False
try:
    import torch
    HAS_TORCH = True
except Exception:
    HAS_TORCH = False
try:
    import psutil
    HAS_PSUTIL = True
except Exception:
    HAS_PSUTIL = False
    print("WARNING: psutil is required for safe operation. Install with: pip install psutil")

# -----------------------------------------------------------------------------
# Configuration validation schema
# -----------------------------------------------------------------------------
if HAS_PYDANTIC:
    class EthicsConfig(BaseModel):
        ece_max: float = Field(default=0.01, ge=0.0, le=1.0)
        rho_bias_max: float = Field(default=1.05, ge=1.0, le=2.0)
        consent_required: bool = True
        eco_ok_required: bool = True

    class IRICConfig(BaseModel):
        rho_max: float = Field(default=0.95, ge=0.0, le=1.0)
        contraction_factor: float = Field(default=0.98, ge=0.1, le=1.0)

    class CAOSConfig(BaseModel):
        kappa: float = Field(default=2.0, ge=1.0, le=10.0)
        pmin: float = Field(default=0.05, ge=0.01, le=1.0)
        pmax: float = Field(default=2.0, ge=1.0, le=10.0)
        chaos_probability: float = Field(default=0.01, ge=0.0, le=1.0)

    class FibonacciConfig(BaseModel):
        enabled: bool = False
        cache: bool = True
        trust_region: bool = True
        l1_ttl_base: float = Field(default=1.0, ge=0.1, le=3600.0)
        l2_ttl_base: float = Field(default=60.0, ge=1.0, le=86400.0)
        max_interval_s: float = Field(default=300.0, ge=10.0, le=86400.0)
        search_method: str = Field(default="fibonacci", regex="^(fibonacci|golden)$")

    class PeninOmegaConfig(BaseModel):
        ethics: EthicsConfig = Field(default_factory=EthicsConfig)
        iric: IRICConfig = Field(default_factory=IRICConfig)
        caos_plus: CAOSConfig = Field(default_factory=CAOSConfig)
        fibonacci: FibonacciConfig = Field(default_factory=FibonacciConfig)
        thresholds: dict = Field(default={"tau_caos": 0.7, "beta_min": 0.02})
        evolution: dict = Field(default={"alpha_0": 0.1})

# Optional: config validation
try:
    from pydantic import BaseModel, Field, ValidationError
    HAS_PYDANTIC = True
except Exception:
    HAS_PYDANTIC = False

# -----------------------------------------------------------------------------
# Configuration and paths
# -----------------------------------------------------------------------------
PKG_VERSION = "6.2.0"
ROOT = Path(os.getenv("PENIN_ROOT", "/opt/penin_omega"))
if not ROOT.exists():
    ROOT = Path.home() / ".penin_omega"
DIRS = {
    "LOG": ROOT / "logs",
    "STATE": ROOT / "state",
    "CACHE": ROOT / "cache",
    "WORM": ROOT / "worm_ledger",
    "SNAPSHOTS": ROOT / "snapshots",
    "MODELS": ROOT / "models",
}
for d in DIRS.values():
    d.mkdir(parents=True, exist_ok=True)

# Structured logging setup
if HAS_STRUCTLOG:
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
    log = structlog.get_logger("Ω-1/8")
else:
    # Fallback to standard logging
    logging.basicConfig(
        level=logging.INFO,
        format="[%(asctime)s][Ω-1/8][%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(DIRS["LOG"] / "omega_core_1of8.log", encoding="utf-8"),
            logging.StreamHandler(sys.stdout),
        ],
    )
    log = logging.getLogger("Ω-1/8")

# Prometheus metrics
class PrometheusMetrics:
    def __init__(self):
        if not HAS_PROMETHEUS:
            return
        
        self.registry = CollectorRegistry()
        
        # Core metrics
        self.penin_alpha = Gauge('penin_alpha', 'Alpha value', registry=self.registry)
        self.penin_delta_linf = Gauge('penin_delta_linf', 'Delta L-infinity', registry=self.registry)
        self.penin_caos = Gauge('penin_caos', 'CAOS+ value', registry=self.registry)
        self.penin_sr = Gauge('penin_sr', 'SR score', registry=self.registry)
        self.penin_g = Gauge('penin_g', 'G score', registry=self.registry)
        self.penin_oci = Gauge('penin_oci', 'OCI score', registry=self.registry)
        self.penin_linf = Gauge('penin_linf', 'L-infinity score', registry=self.registry)
        self.penin_cpu = Gauge('penin_cpu', 'CPU usage', registry=self.registry)
        self.penin_mem = Gauge('penin_mem', 'Memory usage', registry=self.registry)
        
        # Decision counters
        self.penin_decisions_total = Counter('penin_decisions_total', 'Total decisions', ['type'], registry=self.registry)
        self.penin_gate_fail_total = Counter('penin_gate_fail_total', 'Gate failures', ['gate'], registry=self.registry)
        
        # Timing
        self.penin_cycle_duration = Histogram('penin_cycle_duration_seconds', 'Cycle duration', registry=self.registry)
    
    def update_core_metrics(self, xt, result):
        if not HAS_PROMETHEUS:
            return
        
        self.penin_alpha.set(result.get("metrics", {}).get("α_t^Ω", 0))
        self.penin_delta_linf.set(result.get("metrics", {}).get("ΔL∞", 0))
        self.penin_caos.set(result.get("metrics", {}).get("CAOS⁺", 0))
        self.penin_sr.set(result.get("metrics", {}).get("SR", 0))
        self.penin_g.set(result.get("metrics", {}).get("G", 0))
        self.penin_oci.set(result.get("metrics", {}).get("OCI", 0))
        self.penin_linf.set(result.get("metrics", {}).get("L∞", 0))
        self.penin_cpu.set(xt.cpu)
        self.penin_mem.set(xt.mem)
        
        # Decision counter
        decision = result.get("decision", "UNKNOWN")
        self.penin_decisions_total.labels(type=decision).inc()
        
        # Gate failures
        if "failed_gates" in result:
            for gate in result["failed_gates"]:
                self.penin_gate_fail_total.labels(gate=gate).inc()
    
    def start_server(self, port: int = 8000):
        if HAS_PROMETHEUS:
            start_http_server(port, registry=self.registry)
            log.info(f"Prometheus metrics server started on port {port}")

# Global metrics instance
prometheus_metrics = PrometheusMetrics()

# -----------------------------------------------------------------------------
# League Manager (Champion-Challenger)
# -----------------------------------------------------------------------------
class LeagueManager:
    """Manages shadow/canary/promote/rollback operations."""
    
    def __init__(self, core: 'PeninOmegaCore'):
        self.core = core
        self.shadow_models = {}
        self.canary_models = {}
        self.traffic_split = {"shadow": 0.0, "canary": 0.0, "champion": 1.0}
        self.metrics_history = defaultdict(list)
        self.lock = threading.RLock()
    
    def deploy_shadow(self, model_id: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Deploy model in shadow mode (0% traffic)."""
        with self.lock:
            self.shadow_models[model_id] = {
                "config": config,
                "deployed_at": time.time(),
                "metrics": {"requests": 0, "errors": 0, "latency_sum": 0.0}
            }
            
            self.core.worm.record("LEAGUE_SHADOW_DEPLOY", {
                "model_id": model_id,
                "config_hash": _hash_data(config)
            }, self.core.xt)
            
            return {"status": "deployed", "model_id": model_id, "traffic": 0.0}
    
    def promote_to_canary(self, model_id: str, traffic_pct: float = 0.05) -> Dict[str, Any]:
        """Promote shadow model to canary with specified traffic."""
        with self.lock:
            if model_id not in self.shadow_models:
                return {"status": "error", "message": "Model not found in shadow"}
            
            # Move from shadow to canary
            self.canary_models[model_id] = self.shadow_models.pop(model_id)
            self.canary_models[model_id]["canary_traffic"] = traffic_pct
            self.canary_models[model_id]["promoted_at"] = time.time()
            
            # Update traffic split
            self.traffic_split["canary"] = traffic_pct
            self.traffic_split["champion"] = 1.0 - traffic_pct
            
            self.core.worm.record("LEAGUE_CANARY_PROMOTE", {
                "model_id": model_id,
                "traffic_pct": traffic_pct,
                "delta_linf": self.core.xt.delta_linf,
                "gates_ok": self._check_promotion_gates()
            }, self.core.xt)
            
            return {"status": "promoted", "model_id": model_id, "traffic": traffic_pct}
    
    def promote_to_champion(self, model_id: str) -> Dict[str, Any]:
        """Promote canary to champion (100% traffic)."""
        with self.lock:
            if model_id not in self.canary_models:
                return {"status": "error", "message": "Model not found in canary"}
            
            # Check promotion criteria
            gates_ok = self._check_promotion_gates()
            if not gates_ok["all_passed"]:
                return {"status": "rejected", "reason": "Gates failed", "gates": gates_ok}
            
            # Promote to champion
            champion_config = self.canary_models[model_id]["config"]
            self.canary_models.pop(model_id)
            
            # Reset traffic split
            self.traffic_split = {"shadow": 0.0, "canary": 0.0, "champion": 1.0}
            
            # Apply configuration to core
            self.core.cfg.update(champion_config)
            
            self.core.worm.record("LEAGUE_CHAMPION_PROMOTE", {
                "model_id": model_id,
                "config_hash": _hash_data(champion_config),
                "gates": gates_ok,
                "metrics": self.core.xt.to_dict()
            }, self.core.xt)
            
            return {"status": "champion", "model_id": model_id, "traffic": 1.0}
    
    def rollback_canary(self, model_id: str, reason: str = "manual") -> Dict[str, Any]:
        """Rollback canary to shadow."""
        with self.lock:
            if model_id not in self.canary_models:
                return {"status": "error", "message": "Model not found in canary"}
            
            # Move back to shadow
            self.shadow_models[model_id] = self.canary_models.pop(model_id)
            self.shadow_models[model_id]["rollback_reason"] = reason
            self.shadow_models[model_id]["rolled_back_at"] = time.time()
            
            # Reset traffic split
            self.traffic_split = {"shadow": 0.0, "canary": 0.0, "champion": 1.0}
            
            self.core.worm.record("LEAGUE_CANARY_ROLLBACK", {
                "model_id": model_id,
                "reason": reason,
                "metrics": self.core.xt.to_dict()
            }, self.core.xt)
            
            return {"status": "rolled_back", "model_id": model_id, "reason": reason}
    
    def _check_promotion_gates(self) -> Dict[str, Any]:
        """Check if promotion gates are satisfied."""
        xt = self.core.xt
        gates = {
            "delta_linf_ok": xt.delta_linf >= 0.01,
            "sr_ok": xt.sr_score >= 0.8,
            "ece_ok": xt.ece <= 0.01,
            "rho_ok": xt.rho <= 0.95,
            "sigma_ok": xt.sigma_ok if hasattr(xt, 'sigma_ok') else True
        }
        gates["all_passed"] = all(gates.values())
        return gates
    
    def get_status(self) -> Dict[str, Any]:
        """Get current league status."""
        with self.lock:
            return {
                "traffic_split": dict(self.traffic_split),
                "shadow_models": list(self.shadow_models.keys()),
                "canary_models": list(self.canary_models.keys()),
                "champion_metrics": self.core.xt.to_dict()
            }

# -----------------------------------------------------------------------------
# Helpers for determinism and hashing
# -----------------------------------------------------------------------------
def _hash_json(obj: Any) -> str:
    try:
        return hashlib.sha256(json.dumps(obj, sort_keys=True, ensure_ascii=False).encode()).hexdigest()
    except Exception:
        return hashlib.sha256(repr(obj).encode()).hexdigest()

# -----------------------------------------------------------------------------
# Fibonacci toolkit and Zeckendorf
# -----------------------------------------------------------------------------
PHI = (1.0 + math.sqrt(5)) / 2.0
INV_PHI = 1.0 / PHI


class FibonacciResearch:
    """Full Fibonacci research and optimization toolkit."""
    def __init__(self):
        self.fib_cache = {0: 0, 1: 1}
        self.optimization_count = 0
        self.pattern_scores: Dict[str, float] = {}
    def fib_iterative(self, n: int) -> int:
        if n in self.fib_cache:
            return self.fib_cache[n]
        a, b = 0, 1
        for i in range(2, n + 1):
            a, b = b, a + b
            self.fib_cache[i] = b
        return self.fib_cache[n]
    def fib_matrix(self, n: int) -> int:
        if n <= 1:
            return n
        def mm(A, B):
            return [
                [A[0][0] * B[0][0] + A[0][1] * B[1][0], A[0][0] * B[0][1] + A[0][1] * B[1][1]],
                [A[1][0] * B[0][0] + A[1][1] * B[1][0], A[1][0] * B[0][1] + A[1][1] * B[1][1]],
            ]
        def mp(M, p):
            R = [[1, 0], [0, 1]]
            while p > 0:
                if p & 1:
                    R = mm(R, M)
                M = mm(M, M)
                p >>= 1
            return R
        base = [[1, 1], [1, 0]]
        return mp(base, n)[0][1]
    def binet_formula(self, n: int) -> float:
        return (PHI ** n - (-INV_PHI) ** n) / math.sqrt(5)
    def golden_section_search(self, f: Callable[[float], float], a: float, b: float,
                              tol: float = 1e-6, maximize: bool = True) -> float:
        invphi = INV_PHI
        invphi2 = 1.0 - invphi
        h = b - a
        if h <= tol:
            return (a + b) / 2.0
        n = int(math.ceil(math.log(tol / h) / math.log(invphi)))
        c = a + invphi2 * h
        d = a + invphi * h
        fc = f(c)
        fd = f(d)
        if not maximize:
            fc, fd = -fc, -fd
        for _ in range(n - 1):
            if fc < fd:
                a = c
                c, fc = d, fd
                h *= invphi
                d = a + invphi * h
                fd = f(d)
                if not maximize:
                    fd = -fd
            else:
                b = d
                d, fd = c, fc
                h *= invphi
                c = a + invphi2 * h
                fc = f(c)
                if not maximize:
                    fc = -fc
        self.optimization_count += 1
        return (a + b) / 2.0
    def fibonacci_search(self, f: Callable[[float], float], a: float, b: float,
                          tol: float = 1e-6, maximize: bool = True) -> float:
        fib = [0, 1]
        while fib[-1] < (b - a) / tol:
            fib.append(fib[-1] + fib[-2])
        n = len(fib) - 1
        x1 = a + (fib[n - 2] / fib[n]) * (b - a)
        x2 = a + (fib[n - 1] / fib[n]) * (b - a)
        f1, f2 = f(x1), f(x2)
        if not maximize:
            f1, f2 = -f1, -f2
        for k in range(n - 2, 0, -1):
            if f1 < f2:
                a = x1
                x1, f1 = x2, f2
                x2 = a + (fib[k] / fib[k + 1]) * (b - a)
                f2 = f(x2)
                if not maximize:
                    f2 = -f2
            else:
                b = x2
                x2, f2 = x1, f1
                x1 = a + (fib[k - 1] / fib[k + 1]) * (b - a)
                f1 = f(x1)
                if not maximize:
                    f1 = -f1
        self.optimization_count += 1
        return (a + b) / 2.0
    def analyze_fibonacci_patterns(self, seq: List[float]) -> Dict[str, float]:
        if len(seq) < 3:
            return {"ratio_score": 0.0, "pattern_strength": 0.0, "avg_ratio": 0.0}
        ratios = []
        for i in range(1, len(seq)):
            if seq[i - 1] != 0:
                ratios.append(seq[i] / seq[i - 1])
        if not ratios:
            return {"ratio_score": 0.0, "pattern_strength": 0.0, "avg_ratio": 0.0}
        phi_dists = [abs(r - PHI) for r in ratios]
        ratio_score = 1.0 - (sum(phi_dists) / len(phi_dists)) / PHI
        if HAS_NUMPY:
            std_dev = float(np.std(ratios))
        else:
            mean = sum(ratios) / len(ratios)
            std_dev = math.sqrt(sum((r - mean) ** 2 for r in ratios) / len(ratios))
        pattern_strength = 1.0 / (1.0 + std_dev)
        return {
            "ratio_score": max(0.0, ratio_score),
            "pattern_strength": max(0.0, pattern_strength),
            "avg_ratio": sum(ratios) / len(ratios) if ratios else 0.0,
        }
    def fibonacci_retracement_levels(self, high: float, low: float) -> Dict[str, float]:
        diff = high - low
        return {
            "0.0%": high,
            "23.6%": high - 0.236 * diff,
            "38.2%": high - 0.382 * diff,
            "50.0%": high - 0.5 * diff,
            "61.8%": high - 0.618 * diff,
            "78.6%": high - 0.786 * diff,
            "100.0%": low,
        }


class ZeckendorfEncoder:
    """Encode integers uniquely as sums of non‑consecutive Fibonacci numbers."""
    @staticmethod
    def _fib_upto(n: int) -> List[int]:
        fib = [1, 2]
        while fib[-1] < n:
            fib.append(fib[-1] + fib[-2])
        return fib
    @staticmethod
    def encode(n: int) -> List[int]:
        if n < 0:
            raise ValueError("Zeckendorf representation is defined for n >= 0")
        if n == 0:
            return [0]
        fib = ZeckendorfEncoder._fib_upto(n)
        rep: List[int] = []
        i = len(fib) - 1
        while n > 0 and i >= 0:
            if fib[i] <= n:
                rep.append(fib[i])
                n -= fib[i]
                i -= 2
            else:
                i -= 1
        return rep
    @staticmethod
    def encode_as_string(n: int) -> str:
        if n == 0:
            return "0"
        return "Z{" + "+".join(map(str, ZeckendorfEncoder.encode(n))) + "}"


# -----------------------------------------------------------------------------
# Cache (Multi‑level with FibHeap)
# -----------------------------------------------------------------------------
class MultiLevelCache:
    """Three‑level cache with TTL and eviction via lazy min‑heap."""
    def __init__(self, l1_size: int = 1000, l2_size: int = 10000, ttl_l1: int = 1, ttl_l2: int = 60):
        self.l1_cache: OrderedDict[str, Dict[str, Any]] = OrderedDict()
        self.l1_size = l1_size
        self.l1_ttl = ttl_l1
        self.l2_db_path = DIRS["CACHE"] / "l2_cache.db"
        self.l2_db = sqlite3.connect(str(self.l2_db_path), check_same_thread=False)
        self._init_l2_db()
        self.l2_size = l2_size
        self.l2_ttl = ttl_l2
        self.l2_heap = FibHeapLite()
        self.l2_nodes: Dict[str, Tuple] = {}
        self.l3_redis = None
        self.redis_namespace = f"penin_omega_v{PKG_VERSION.replace('.', '_')}"
        if HAS_REDIS:
            try:
                self.l3_redis = redis.Redis(host='localhost', port=6379, db=0, decode_responses=False)
                self.l3_redis.ping()
            except Exception:
                self.l3_redis = None
        self.stats = defaultdict(lambda: {"hits": 0, "misses": 0, "evictions": 0})
        self._lock = threading.RLock()
    def _init_l2_db(self):
        cursor = self.l2_db.cursor()
        
        # Configure SQLite for better performance and concurrency
        cursor.execute('PRAGMA journal_mode=WAL')
        cursor.execute('PRAGMA synchronous=NORMAL')
        cursor.execute('PRAGMA busy_timeout=3000')
        cursor.execute('PRAGMA cache_size=10000')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS cache (
                key TEXT PRIMARY KEY,
                value BLOB,
                timestamp REAL,
                access_count INTEGER DEFAULT 0,
                last_access REAL
            )
        ''')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON cache(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_access ON cache(access_count)')
        self.l2_db.commit()
    def _serialize(self, obj: Any) -> bytes: return pickle.dumps(obj)
    def _deserialize(self, b: bytes) -> Any: return pickle.loads(b)
    def _promote_to_l1(self, key: str, value: Any):
        if len(self.l1_cache) >= self.l1_size:
            evicted_key, _ = self.l1_cache.popitem(last=False)
            self.stats[evicted_key]["evictions"] += 1
        self.l1_cache[key] = {"value": value, "timestamp": time.time()}
        self.l1_cache.move_to_end(key)
    def _promote_to_l2(self, key: str, value: Any):
        value_bytes = self._serialize(value)
        cursor = self.l2_db.cursor()
        now = time.time()
        cursor.execute("SELECT COUNT(*) FROM cache")
        count = cursor.fetchone()[0]
        if count >= self.l2_size:
            for _ in range(max(1, self.l2_size // 10)):
                evicted = self.l2_heap.extract_min()
                if evicted:
                    _, evicted_key = evicted
                    cursor.execute("DELETE FROM cache WHERE key = ?", (evicted_key,))
                    self.stats[evicted_key]["evictions"] += 1
                    self.l2_nodes.pop(evicted_key, None)
        cursor.execute(
            "INSERT OR REPLACE INTO cache (key, value, timestamp, last_access) VALUES (?, ?, ?, ?)",
            (key, value_bytes, now, now)
        )
        self.l2_db.commit()
        prio = now
        if key in self.l2_nodes:
            self.l2_heap.decrease_key(key, prio)
        else:
            self.l2_nodes[key] = self.l2_heap.insert(prio, key)
    def get(self, key: str, default: Any = None) -> Any:
        with self._lock:
            if key in self.l1_cache:
                entry = self.l1_cache[key]
                if time.time() - entry["timestamp"] < self.l1_ttl:
                    self.stats[key]["hits"] += 1
                    self.l1_cache.move_to_end(key)
                    return entry["value"]
                else:
                    del self.l1_cache[key]
            cursor = self.l2_db.cursor()
            cursor.execute("SELECT value, timestamp FROM cache WHERE key = ?", (key,))
            row = cursor.fetchone()
            if row:
                value_bytes, timestamp = row
                if time.time() - timestamp < self.l2_ttl:
                    value = self._deserialize(value_bytes)
                    self._promote_to_l1(key, value)
                    cursor.execute(
                        "UPDATE cache SET access_count = access_count + 1, last_access = ? WHERE key = ?",
                        (time.time(), key)
                    )
                    self.l2_db.commit()
                    if key in self.l2_nodes:
                        self.l2_heap.decrease_key(key, time.time())
                    self.stats[key]["hits"] += 1
                    return value
            if self.l3_redis:
                try:
                    redis_key = f"{self.redis_namespace}:{key}"
                    value_bytes = self.l3_redis.get(redis_key)
                    if value_bytes:
                        value = self._deserialize(value_bytes)
                        self._promote_to_l1(key, value)
                        self._promote_to_l2(key, value)
                        self.stats[key]["hits"] += 1
                        return value
                except Exception:
                    pass
            self.stats[key]["misses"] += 1
            return default
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        with self._lock:
            self._promote_to_l1(key, value)
            self._promote_to_l2(key, value)
            if self.l3_redis:
                try:
                    value_bytes = self._serialize(value)
                    redis_key = f"{self.redis_namespace}:{key}"
                    self.l3_redis.setex(
                        redis_key, ttl or self.l2_ttl, value_bytes
                    )
                except Exception:
                    pass
    def clear(self):
        with self._lock:
            self.l1_cache.clear()
            self.l2_db.execute("DELETE FROM cache")
            self.l2_db.commit()
            self.l2_heap = FibHeapLite()
            self.l2_nodes.clear()
            if self.l3_redis:
                try:
                    pattern = f"{self.redis_namespace}:*"
                    for key in self.l3_redis.scan_iter(pattern):
                        self.l3_redis.delete(key)
                except Exception:
                    pass


class FibHeapLite:
    """Lazy min‑heap with tombstones for decrease_key support."""
    def __init__(self):
        import heapq
        self.heap: List[Tuple[float, int, str]] = []
        self.entry_fresh: Dict[str, Tuple[float, int, str]] = {}
        self.invalid: set = set()
        self._heapq = heapq
        self._counter = 0
    def insert(self, key: float, value: str):
        self._counter += 1
        token = (key, self._counter, value)
        self.entry_fresh[value] = token
        self._heapq.heappush(self.heap, token)
        return token
    def decrease_key(self, value: str, new_key: float):
        old = self.entry_fresh.get(value)
        if old:
            self.invalid.add(old)
        return self.insert(new_key, value)
    def extract_min(self) -> Optional[Tuple[float, str]]:
        while self.heap:
            key, _, val = self._heapq.heappop(self.heap)
            token = (key, _, val)
            if token in self.invalid:
                self.invalid.remove(token)
                continue
            if self.entry_fresh.get(val) == token:
                del self.entry_fresh[val]
                return key, val
        return None


# -----------------------------------------------------------------------------
# WORM Ledger
# -----------------------------------------------------------------------------
class WORMLedger:
    """Write‑once, read‑many ledger with hash chain and optional Zeckendorf."""
    def __init__(self, path: Path = DIRS["WORM"] / "omega_core_1of8.db"):
        self.db = sqlite3.connect(str(path), check_same_thread=False)
        self._init_db()
        self._lock = threading.Lock()
        self.tail = self._get_last_hash()
    def _init_db(self):
        cursor = self.db.cursor()
        try:
            cursor.execute('PRAGMA journal_mode=WAL')
            cursor.execute('PRAGMA synchronous=NORMAL')
            cursor.execute('PRAGMA busy_timeout=3000')
        except Exception:
            pass
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                etype TEXT,
                data TEXT,
                ts TEXT,
                prev TEXT,
                hash TEXT,
                zeck TEXT
            )
            """
        )
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_ts ON events(ts)")
        self.db.commit()
    def _get_last_hash(self) -> str:
        c = self.db.cursor()
        c.execute("SELECT hash FROM events ORDER BY id DESC LIMIT 1")
        row = c.fetchone()
        return row[0] if row else "genesis"
    def record(self, etype: str, data: Dict[str, Any], state_for_zeck: Optional[OmegaMEState] = None) -> str:
        with self._lock:
            ts = datetime.now(timezone.utc).isoformat()
            zeck = None
            if state_for_zeck:
                mix = int(abs(state_for_zeck.delta_linf) * 1e6) + int(state_for_zeck.caos_plus * 1e6) + state_for_zeck.cycle
                zeck = ZeckendorfEncoder.encode_as_string(abs(mix))
            payload = {"etype": etype, "data": data, "ts": ts, "prev": self.tail}
            event_hash = hashlib.sha256(json.dumps(payload, sort_keys=True, ensure_ascii=False).encode()).hexdigest()
            cursor = self.db.cursor()
            cursor.execute(
                "INSERT INTO events (etype, data, ts, prev, hash, zeck) VALUES (?, ?, ?, ?, ?, ?)",
                (etype, json.dumps(data, ensure_ascii=False), ts, self.tail, event_hash, zeck),
            )
            self.db.commit()
            self.tail = event_hash
            return event_hash
    def verify_chain(self) -> Tuple[bool, Optional[str]]:
        c = self.db.cursor()
        c.execute("SELECT etype, data, ts, prev, hash FROM events ORDER BY id")
        prev = "genesis"
        for i, (etype, data, ts, stored_prev, stored_hash) in enumerate(c.fetchall(), 1):
            if stored_prev != prev:
                return False, f"Chain break at row {i}"
            payload = {"etype": etype, "data": json.loads(data), "ts": ts, "prev": stored_prev}
            calc = hashlib.sha256(json.dumps(payload, sort_keys=True, ensure_ascii=False).encode()).hexdigest()
            if calc != stored_hash:
                return False, f"Hash mismatch at row {i}"
            prev = stored_hash
        return True, None


# -----------------------------------------------------------------------------
# State class
# -----------------------------------------------------------------------------
@dataclass
class OmegaMEState:
    cycle: int = 0
    ts: float = field(default_factory=time.time)
    l_inf: float = 0.0
    l_inf_prev: float = 0.0
    delta_linf: float = 0.0
    rsi: float = 0.6
    synergy: float = 0.6
    novelty: float = 0.5
    stability: float = 0.7
    viability: float = 0.8
    cost: float = 0.2
    C: float = 0.6
    A: float = 0.6
    O: float = 0.6
    S: float = 0.6
    caos_plus: float = 1.0
    caos_harmony: float = 1.0
    caos_stable: bool = True
    sr_score: float = 1.0
    C_cal: float = 0.8
    E_ok: float = 1.0
    M: float = 0.7
    A_eff: float = 0.6
    g_score: float = 1.0
    modules: List[float] = field(default_factory=lambda: [0.7] * 8)
    oci_score: float = 1.0
    memory: float = 0.8
    flow: float = 0.7
    policy: float = 0.9
    feedback: float = 0.6
    sigma_ok: bool = True
    ece: float = 0.0
    bias: float = 1.0
    consent: bool = True
    eco: bool = True
    rho: float = 0.5
    uncertainty: float = 0.3
    throughput: float = 0.0
    latency_ms: float = 0.0
    cpu: float = 0.0
    mem: float = 0.0
    alpha_0: float = 0.1
    alpha_omega: float = 0.0
    trust_radius: float = 0.1
    kill_switch: bool = False
    fib_optimizations: int = 0
    pattern_score: float = 0.0
    zeckendorf_hash: str = "0"
    def to_dict(self) -> Dict[str, Any]: return asdict(self)


# -----------------------------------------------------------------------------
# Engines
# -----------------------------------------------------------------------------
class SigmaGuard:
    def __init__(self, cfg: Dict[str, Any]):
        e = cfg.get("ethics", {})
        self.ece_max = e.get("ece_max", 0.01)
        self.bias_max = e.get("rho_bias_max", 1.05)
        self.require_consent = e.get("consent_required", True)
        self.require_eco = e.get("eco_ok_required", True)
        self.rho_max = cfg.get("iric", {}).get("rho_max", 0.95)
    def check(self, xt: OmegaMEState) -> Tuple[bool, List[str]]:
        violations = []
        if xt.ece > self.ece_max: violations.append(f"ECE {xt.ece:.4f} > {self.ece_max}")
        if xt.bias > self.bias_max: violations.append(f"Bias {xt.bias:.3f} > {self.bias_max}")
        if self.require_consent and not xt.consent: violations.append("Consent=False")
        if self.require_eco and not xt.eco: violations.append("Eco=False")
        if xt.rho >= self.rho_max: violations.append(f"Risk {xt.rho:.3f} >= {self.rho_max}")
        xt.sigma_ok = len(violations) == 0
        return xt.sigma_ok, violations

class IRtoIC:
    def __init__(self, cfg: Dict[str, Any], use_phi: bool = False):
        self.rho_max = cfg.get("iric", {}).get("rho_max", 0.95)
        self.contraction = INV_PHI if use_phi else cfg.get("iric", {}).get("contraction_factor", 0.98)
        # Removed ThreadPoolExecutor: checks are synchronous and cheap
    def safe(self, xt: OmegaMEState) -> bool:
        return (
            (xt.rho < self.rho_max)
            and (xt.uncertainty < 0.9)
            and (xt.cpu < 0.95 and xt.mem < 0.95)
        )
    def contract(self, xt: OmegaMEState) -> None:
        xt.rho *= self.contraction
        xt.uncertainty *= self.contraction

class CAOSPlusEngine:
    def __init__(self, cfg: Dict[str, Any], fib: FibonacciResearch, seed: int = 42):
        c = cfg.get("caos_plus", {})
        self.kappa = c.get("kappa", 2.0)
        self.pmin = c.get("pmin", 0.05)
        self.pmax = c.get("pmax", 2.0)
        self.pchaos = c.get("chaos_probability", 0.01)
        self.fib = fib
        self.seed = seed
        self.rng = random.Random(seed)
        # EWMA for stability check (for Fibonacci boost gating)
        self._ewma_alpha = float(c.get("ewma_alpha", 0.2))
        self._ewma: Optional[float] = None
    def compute(self, xt: OmegaMEState) -> float:
        if self.rng.random() < self.pchaos:
            fac = self.rng.uniform(0.9, 1.1)
            xt.C *= fac; xt.A *= fac; xt.O *= fac; xt.S *= fac
        C, A, O, S = max(0.0, xt.C), max(0.0, xt.A), max(0.0, xt.O), max(0.0, xt.S)
        base = 1.0 + self.kappa * C * A
        exponent = max(self.pmin, min(self.pmax, O * S))
        val = base ** exponent
        patt = self.fib.analyze_fibonacci_patterns([C, A, O, S])
        # Clamp Fibonacci boost to max 5% with stability check
        boost_factor = min(0.05, 0.1 * patt["pattern_strength"])
        
        # EWMA stability window check
        if not hasattr(self, 'stability_window'):
            self.stability_window = deque(maxlen=10)
        
        self.stability_window.append(patt["pattern_strength"])
        
        # Only apply boost if pattern is stable (low variance in recent window)
        if len(self.stability_window) >= 5:
            window_mean = sum(self.stability_window) / len(self.stability_window)
            window_var = sum((x - window_mean) ** 2 for x in self.stability_window) / len(self.stability_window)
            if window_var < 0.01:  # Stable pattern
                val *= (1.0 + boost_factor)
        
        # Maintain EWMA of delta L∞ as stability proxy
        try:
            delta_signal = abs(xt.delta_linf)
            if self._ewma is None:
                self._ewma = delta_signal
            else:
                self._ewma = self._ewma_alpha * delta_signal + (1 - self._ewma_alpha) * self._ewma
            xt.caos_stable = self._ewma is not None and self._ewma < 0.05
        except Exception:
            xt.caos_stable = False
        xt.pattern_score = patt["pattern_strength"]
        xt.caos_plus = val
        xt.caos_harmony = (C + A) / (O + S if (O + S) > 1e-9 else 1.0)
        return val

class CAOSExplorationEngine:
    """Separate CAOS+ exploration engine for variant selection (not promotion)."""
    
    def __init__(self, cfg: Dict[str, Any], seed: int = 42):
        e = cfg.get("caos_exploration", {})
        self.budget = e.get("exploration_budget", 0.05)  # 5% budget for exploration
        self.max_boost = e.get("max_boost", 0.05)  # Max 5% boost
        self.exploration_threshold = e.get("threshold", 0.7)
        self.seed = seed
        self.rng = random.Random(seed)
        self.exploration_history = deque(maxlen=100)
        self.gates = {"budget_ok": True, "threshold_ok": True}
    
    def compute_exploration_score(self, xt: OmegaMEState, variant_id: str = "default") -> float:
        """Compute exploration score for variant selection only."""
        # Check exploration gates
        self.gates["budget_ok"] = len(self.exploration_history) < self.budget * 100
        self.gates["threshold_ok"] = xt.caos_plus >= self.exploration_threshold
        
        if not all(self.gates.values()):
            return 0.0  # No exploration if gates fail
        
        # Compute exploration bonus (separate from promotion logic)
        base_exploration = self.rng.uniform(0.0, self.max_boost)
        
        # Adjust based on recent exploration success
        if len(self.exploration_history) >= 10:
            recent_success = sum(1 for h in list(self.exploration_history)[-10:] if h.get("success", False))
            success_rate = recent_success / 10.0
            base_exploration *= (1.0 + success_rate * 0.2)  # Bonus for successful exploration
        
        # Record exploration attempt
        self.exploration_history.append({
            "variant_id": variant_id,
            "score": base_exploration,
            "timestamp": time.time(),
            "success": base_exploration > 0.02  # Arbitrary success threshold
        })
        
        return base_exploration
    
    def should_explore(self, xt: OmegaMEState) -> bool:
        """Determine if exploration should be attempted."""
        return all(self.gates.values()) and xt.sr_score >= 0.8
    
    def get_exploration_stats(self) -> Dict[str, Any]:
        """Get exploration statistics."""
        if not self.exploration_history:
            return {"attempts": 0, "success_rate": 0.0, "avg_score": 0.0}
        
        attempts = len(self.exploration_history)
        successes = sum(1 for h in self.exploration_history if h.get("success", False))
        avg_score = sum(h.get("score", 0) for h in self.exploration_history) / attempts
        
        return {
            "attempts": attempts,
            "success_rate": successes / attempts,
            "avg_score": avg_score,
            "gates": dict(self.gates)
        }

class SREngine:
    def __init__(self, cfg: Dict[str, Any]):
        s = cfg.get("sr_omega", {})
        self.weights = s.get("weights", {"C": 0.2, "E": 0.4, "M": 0.3, "A": 0.1})
        self.tau = s.get("tau_sr", 0.8)
    def compute(self, xt: OmegaMEState) -> float:
        comps = [
            (max(1e-6, xt.C_cal), self.weights["C"]),
            (max(1e-6, xt.E_ok), self.weights["E"]),
            (max(1e-6, xt.M), self.weights["M"]),
            (max(1e-6, xt.A_eff), self.weights["A"]),
        ]
        denom = sum(w / v for v, w in comps)
        xt.sr_score = 1.0 / max(1e-6, denom)
        return xt.sr_score
    def gate(self, xt: OmegaMEState) -> bool:
        return xt.sr_score >= self.tau

class GlobalCoherence:
    def __init__(self, cfg: Dict[str, Any]):
        g = cfg.get("omega_sigma", {})
        self.weights = g.get("weights", [1.0 / 8] * 8)
        self.tau = g.get("tau_g", 0.7)
    def compute(self, xt: OmegaMEState) -> float:
        if len(xt.modules) != 8:
            xt.modules = [0.7] * 8
        denom = 0.0
        for w, s in zip(self.weights, xt.modules):
            if s <= 0:
                xt.g_score = 0.0
                return 0.0
            denom += w / s
        xt.g_score = 1.0 / max(1e-6, denom)
        return xt.g_score
    def gate(self, xt: OmegaMEState) -> bool:
        return xt.g_score >= self.tau

class OCIEngine:
    def __init__(self, cfg: Dict[str, Any]):
        o = cfg.get("oci", {})
        self.weights = o.get("weights", [0.25, 0.25, 0.25, 0.25])
        self.tau = o.get("tau_oci", 0.9)
    def compute(self, xt: OmegaMEState) -> float:
        comps = [
            (max(1e-6, xt.memory), self.weights[0]),
            (max(1e-6, xt.flow), self.weights[1]),
            (max(1e-6, xt.policy), self.weights[2]),
            (max(1e-6, xt.feedback), self.weights[3]),
        ]
        denom = sum(w / v for v, w in comps)
        xt.oci_score = 1.0 / max(1e-6, denom)
        return xt.oci_score
    def gate(self, xt: OmegaMEState) -> bool:
        return xt.oci_score >= self.tau

class LInfinityScore:
    def __init__(self, cfg: Dict[str, Any]):
        l = cfg.get("linf_placar", {})
        self.weights = l.get("weights", {"rsi": 0.2, "synergy": 0.2, "novelty": 0.2,
                                            "stability": 0.2, "viability": 0.15, "cost": 0.05})
        self.lambda_c = l.get("lambda_c", 0.1)
    def compute(self, xt: OmegaMEState) -> float:
        metrics = [
            (max(1e-6, xt.rsi), self.weights["rsi"]),
            (max(1e-6, xt.synergy), self.weights["synergy"]),
            (max(1e-6, xt.novelty), self.weights["novelty"]),
            (max(1e-6, xt.stability), self.weights["stability"]),
            (max(1e-6, xt.viability), self.weights["viability"]),
            (max(1e-6, 1.0 - xt.cost), self.weights["cost"]),
        ]
        denom = sum(w / v for v, w in metrics)
        base = 1.0 / max(1e-6, denom)
        penalty = math.exp(-self.lambda_c * xt.cost)
        eth_gate = 1.0 if xt.sigma_ok else 0.0
        risk_gate = 1.0 if xt.rho < 0.95 else 0.0
        xt.l_inf_prev = xt.l_inf
        xt.l_inf = base * penalty * eth_gate * risk_gate
        xt.delta_linf = xt.l_inf - xt.l_inf_prev
        return xt.l_inf


# -----------------------------------------------------------------------------
# Fibonacci manager for TTL, trust region and LR search
# -----------------------------------------------------------------------------
class FibonacciSchedule:
    def __init__(self, base: float, max_interval: float):
        self.base = float(base)
        self.max = float(max_interval)
        self.i = 1
        self.fr = FibonacciResearch()
    def next(self) -> float:
        val = min(self.max, self.base * float(self.fr.fib_iterative(self.i)))
        self.i += 1
        return max(self.base, val)
    def reset(self):
        self.i = 1

class FibonacciManager:
    def __init__(self, cfg: Dict[str, Any], worm: WORMLedger, fib: FibonacciResearch):
        self.enabled = bool(cfg.get("enabled", False))
        self.cache_enabled = bool(cfg.get("cache", True))
        self.trust_enabled = bool(cfg.get("trust_region", True))
        self.l1b = float(cfg.get("l1_ttl_base", 1.0))
        self.l2b = float(cfg.get("l2_ttl_base", 60.0))
        self.maxi = float(cfg.get("max_interval_s", 300.0))
        trust_growth = cfg.get("trust_growth")
        trust_shrink = cfg.get("trust_shrink")
        self.grow = float(trust_growth if trust_growth is not None else PHI ** 0.125)
        self.shrk = float(trust_shrink if trust_shrink is not None else INV_PHI ** 0.125)
        self.method = str(cfg.get("search_method", "fibonacci")).lower()
        self.s1 = FibonacciSchedule(self.l1b, self.maxi)
        self.s2 = FibonacciSchedule(self.l2b, self.maxi)
        self.worm = worm
        self.fib = fib
    def apply_cache(self, cache: MultiLevelCache):
        if not (self.enabled and self.cache_enabled): return
        cache.l1_ttl = int(self.s1.next())
        cache.l2_ttl = int(self.s2.next())
        self.worm.record("FIBONACCI_TICK", {
            "l1_ttl": cache.l1_ttl,
            "l2_ttl": cache.l2_ttl,
        })
    def modulate_trust(self, xt: OmegaMEState):
        if not (self.enabled and self.trust_enabled): return
        if xt.delta_linf > 0.02:
            xt.trust_radius = min(0.5, xt.trust_radius * self.grow)
        else:
            xt.trust_radius = max(0.01, xt.trust_radius * self.shrk)
    def optimize_lr(self, f: Callable[[float], float], a: float = 0.01, b: float = 1.0) -> float:
        return self.fib.fibonacci_search(f, a, b, maximize=True) if self.method == "fibonacci" else self.fib.golden_section_search(f, a, b, maximize=True)


# -----------------------------------------------------------------------------
# PeninOmegaCore
# -----------------------------------------------------------------------------
class PeninOmegaCore:
    def __init__(self, config: Optional[Dict[str, Any]] = None, seed: int = 42):
        self.cfg = self._load_config(config)
        self.seed = seed
        self.cycle_seed = seed
        self._boot_seed = seed  # For compatibility
        random.seed(seed)  # Set global seed for determinism
        self.worm = WORMLedger()
        self.cache = MultiLevelCache()
        self.fibR = FibonacciResearch()
        self.fib = FibonacciManager(self.cfg.get("fibonacci", {}), self.worm, self.fibR)
        use_phi = self.fib.enabled
        self.sigma = SigmaGuard(self.cfg)
        self.iric = IRtoIC(self.cfg, use_phi=use_phi)
        self.caos = CAOSPlusEngine(self.cfg, self.fibR, seed)
        self.caos_explorer = CAOSExplorationEngine(self.cfg, seed)
        self.sr = SREngine(self.cfg)
        self.gc = GlobalCoherence(self.cfg)
        self.oci = OCIEngine(self.cfg)
        self.linf = LInfinityScore(self.cfg)
        self.xt = OmegaMEState()
        self.metrics = {"cycles": 0, "promotions": 0, "rollbacks": 0, "extinctions": 0}
        self.league = LeagueManager(self)
        self._register_boot()
        if self.fib.enabled and self.fib.cache_enabled:
            self.fib.apply_cache(self.cache)
        self.pool = ThreadPoolExecutor(max_workers=8)
        self.ppool = ProcessPoolExecutor(max_workers=4)
        
        # Start Prometheus metrics server if enabled
        if HAS_PROMETHEUS and self.cfg.get("prometheus", {}).get("enabled", False):
            port = self.cfg.get("prometheus", {}).get("port", 8000)
            prometheus_metrics.start_server(port)
        
        # Start League API server if enabled
        if HAS_HTTP_SERVER and self.cfg.get("league", {}).get("enabled", False):
            port = self.cfg.get("league", {}).get("port", 8001)
            self.league_server = start_league_server(self, port)
        else:
            self.league_server = None
    def _load_config(self, custom: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        default = {
            "ethics": {"ece_max": 0.01, "rho_bias_max": 1.05, "consent_required": True, "eco_ok_required": True},
            "iric": {"rho_max": 0.95, "contraction_factor": 0.98},
            "caos_plus": {"kappa": 2.0, "pmin": 0.05, "pmax": 2.0, "chaos_probability": 0.01},
            "sr_omega": {"weights": {"C": 0.2, "E": 0.4, "M": 0.3, "A": 0.1}, "tau_sr": 0.8},
            "omega_sigma": {"weights": [1.0 / 8] * 8, "tau_g": 0.7},
            "oci": {"weights": [0.25, 0.25, 0.25, 0.25], "tau_oci": 0.9},
            "linf_placar": {"weights": {"rsi": 0.2, "synergy": 0.2, "novelty": 0.2,
                                           "stability": 0.2, "viability": 0.15, "cost": 0.05},
                              "lambda_c": 0.1},
            "fibonacci": {"enabled": False, "cache": True, "trust_region": True,
                           "l1_ttl_base": 1, "l2_ttl_base": 60, "max_interval_s": 300,
                           "trust_growth": None, "trust_shrink": None, "search_method": "fibonacci"},
            "thresholds": {"tau_caos": 0.7, "beta_min": 0.02},
            "evolution": {"alpha_0": 0.1},
        }
        config = _deep_merge(default, custom or {})
        
        # Validate configuration if pydantic is available
        if HAS_PYDANTIC:
            try:
                validated_config = PeninOmegaConfig(**config)
                # Convert back to dict for compatibility
                config.update(validated_config.dict())
                log.info("Configuration validated successfully")
            except ValidationError as e:
                log.error(f"Configuration validation failed: {e}")
                raise ValueError(f"Invalid configuration: {e}")
        else:
            log.warning("pydantic not available - configuration validation skipped")
        
        return config
    def _register_boot(self):
        self.worm.record("BOOT", {
            "version": PKG_VERSION,
            "phi": PHI,
            "inv_phi": INV_PHI,
            "fibonacci_enabled": self.fib.enabled,
            "seed": self._boot_seed,
        }, self.xt)
    async def master_equation_cycle(self, external_metrics: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
        result = {"success": False, "decision": None, "metrics": {}}
        t0 = time.time()
        
        # Update cycle seed for determinism
        self.cycle_seed = (self.cycle_seed * 1103515245 + 12345) & 0x7fffffff
        random.seed(self.cycle_seed)
        
        # Log seed and random state for reproducibility
        randstate = random.getstate()
        self.worm.record("CYCLE_START", {
            "cycle": self.xt.cycle,
            "seed": self.cycle_seed,
            "randstate_hash": _hash_data(str(randstate))
        }, self.xt)
        
        try:
            # Warn if psutil not available but continue for testing
            if not HAS_PSUTIL:
                log.warning("psutil not available - using fallback resource monitoring")
            if external_metrics:
                for k, v in external_metrics.items():
                    if hasattr(self.xt, k) and v is not None: 
                        setattr(self.xt, k, float(v))
            
            # Get resource usage
            if HAS_PSUTIL:
                self.xt.cpu = psutil.cpu_percent(interval=None) / 100.0
                self.xt.mem = psutil.virtual_memory().percent / 100.0
                
                # Fail-closed: assume high usage if resources are critical
                if self.xt.cpu > 0.95 or self.xt.mem > 0.95:
                    result.update({"decision": "ABORT", "reason": "RESOURCE_CRITICAL", "cpu": self.xt.cpu, "mem": self.xt.mem})
                    self.worm.record("CYCLE_ABORT", result, self.xt)
                    return result
            else:
                # Fallback values when psutil not available
                self.xt.cpu = 0.5  # Assume moderate usage
                self.xt.mem = 0.5
            ok, violations = self.sigma.check(self.xt)
            if not ok:
                result.update({"decision": "ABORT", "reason": "SIGMA_GUARD", "violations": violations,
                               "gate_result": {"gate": "SIGMA_GUARD", "details": violations}})
                self.worm.record("CYCLE_ABORT", result, self.xt)
                return result
            if not self.iric.safe(self.xt):
                self.iric.contract(self.xt)
                result.update({"decision": "ABORT", "reason": "IRIC_CONTRACT",
                               "gate_result": {"gate": "IRIC", "metric": "cpu/mem/rho", "value": {"cpu": self.xt.cpu, "mem": self.xt.mem, "rho": self.xt.rho}, "threshold": {"cpu": 0.95, "mem": 0.95, "rho": self.cfg.get("iric", {}).get("rho_max", 0.95)}}})
                self.worm.record("CYCLE_ABORT", result, self.xt)
                return result
            # Log seed/randstate for replay determinism
            self.worm.record("CYCLE_SEED", {"seed": self.cycle_seed}, self.xt)
            l_score = self.linf.compute(self.xt)
            result["metrics"]["L∞"] = l_score
            result["metrics"]["ΔL∞"] = self.xt.delta_linf
            caos_val = self.caos.compute(self.xt)
            result["metrics"]["CAOS⁺"] = caos_val
            result["metrics"]["harmony"] = self.xt.caos_harmony
            sr_val = self.sr.compute(self.xt)
            result["metrics"]["SR"] = sr_val
            g_val = self.gc.compute(self.xt)
            result["metrics"]["G"] = g_val
            oci_val = self.oci.compute(self.xt)
            result["metrics"]["OCI"] = oci_val
            alpha = self._compute_alpha()
            result["metrics"]["α_t^Ω"] = alpha
            gates = []
            gate_trace: List[Dict[str, Any]] = []
            if not self.sr.gate(self.xt):
                gates.append("SR_GATE"); gate_trace.append({"gate": "SR", "value": self.xt.sr_score, "threshold": self.sr.tau})
            if not self.gc.gate(self.xt):
                gates.append("G_GATE"); gate_trace.append({"gate": "G", "value": self.xt.g_score, "threshold": self.gc.tau})
            if not self.oci.gate(self.xt):
                gates.append("OCI_GATE"); gate_trace.append({"gate": "OCI", "value": self.xt.oci_score, "threshold": self.oci.tau})
            if self.xt.delta_linf < self.cfg["thresholds"]["beta_min"]:
                gates.append("ΔL∞_GATE"); gate_trace.append({"gate": "ΔL∞", "value": self.xt.delta_linf, "threshold": self.cfg["thresholds"]["beta_min"]})
            if self.xt.caos_plus < self.cfg["thresholds"]["tau_caos"]:
                gates.append("CAOS⁺_GATE"); gate_trace.append({"gate": "CAOS⁺", "value": self.xt.caos_plus, "threshold": self.cfg["thresholds"]["tau_caos"]})
            if gates:
                result.update({"decision": "ROLLBACK", "reason": "GATES_FAILED", "failed_gates": gates, "gate_trace": gate_trace})
                self.metrics["rollbacks"] += 1
                self.xt.cycle += 1  # Increment even on gate failure
                self.metrics["cycles"] += 1
                self.worm.record("ROLLBACK", result, self.xt)
                return result
            step = alpha * self.xt.delta_linf
            lr_opt = 1.0
            if self.fib.enabled:
                def lr_score(lr: float) -> float:
                    harm_bonus = 1.0 - min(1.0, abs(self.xt.caos_harmony - PHI) / PHI)
                    return step * lr * (1.0 + 0.1 * harm_bonus)
                lr_opt = self.fib.optimize_lr(lr_score, 0.5, 2.0)
                self.worm.record("FIBONACCI_OPT", {"lr_opt": lr_opt, "opt_count": self.fibR.optimization_count}, self.xt)
            step_opt = step * lr_opt
            self.xt.rsi       += step_opt * 0.08
            self.xt.synergy   += step_opt * 0.07
            self.xt.novelty   += step_opt * 0.05
            self.xt.stability += step_opt * 0.06
            self.xt.viability += step_opt * 0.05
            self.xt.cost       = max(0.0, self.xt.cost - step_opt * 0.03)
            self.xt.C = min(1.0, self.xt.C + step_opt * 0.04)
            self.xt.A = min(1.0, self.xt.A + step_opt * 0.05)
            self.xt.O = min(1.0, self.xt.O + step_opt * 0.03)
            self.xt.S = min(1.0, self.xt.S + step_opt * 0.02)
            self.xt.C_cal = min(1.0, self.xt.C_cal + step_opt * 0.03)
            self.xt.M     = min(1.0, self.xt.M     + step_opt * 0.04)
            self.xt.A_eff = min(1.0, self.xt.A_eff + step_opt * 0.05)
            if self.fib.enabled:
                self.fib.modulate_trust(self.xt)
            if step_opt > 0:
                # TOCTOU protection: capture state immediately before promotion
                pre_hash = _hash_data(self.xt.to_dict())
                
                # Apply promotion changes
                result.update({"success": True, "decision": "PROMOTE", "evolution_step": step_opt})
                self.metrics["promotions"] += 1
                
                # Capture state immediately after promotion
                post_hash = _hash_data(self.xt.to_dict())
                
                # Atomic PROMOTE_ATTEST event
                gate_trace = {
                    "sr_gate": self.sr.gate(self.xt),
                    "g_gate": self.gc.gate(self.xt), 
                    "oci_gate": self.oci.gate(self.xt),
                    "delta_linf_gate": self.xt.delta_linf >= self.cfg["thresholds"]["beta_min"],
                    "caos_gate": self.xt.caos_plus >= self.cfg["thresholds"]["tau_caos"]
                }
                
                promote_attest = {
                    "pre_hash": pre_hash,
                    "post_hash": post_hash,
                    "gate_trace": gate_trace,
                    "config_hash": _hash_data(self.cfg),
                    "seed": getattr(self, 'cycle_seed', 42),
                    "delta_metrics": {
                        "step": step_opt,
                        "alpha": alpha,
                        "ΔL∞": self.xt.delta_linf
                    }
                }
                
                self.worm.record("PROMOTE_ATTEST", promote_attest, self.xt)
            else:
                result.update({"decision": "ROLLBACK", "reason": "NEGATIVE_STEP"})
                self.metrics["rollbacks"] += 1
                self.worm.record("ROLLBACK", {"step": step_opt, "alpha": alpha, "ΔL∞": self.xt.delta_linf}, self.xt)
            
            # Always increment cycle count
            self.xt.cycle += 1
            self.metrics["cycles"] += 1
            elapsed = max(1e-6, time.time() - t0)
            self.xt.latency_ms = elapsed * 1000.0
            self.xt.throughput = 1.0 / elapsed
            if self.fib.enabled:
                self.fib.apply_cache(self.cache)
            self.worm.record("MASTER_EQ", {"cycle": self.xt.cycle, "metrics": result["metrics"], "step": step_opt}, self.xt)
            
            # Update Prometheus metrics
            prometheus_metrics.update_core_metrics(self.xt, result)
            prometheus_metrics.penin_cycle_duration.observe(elapsed)
            
            # Log exploration stats (separate from promotion)
            if self.caos_explorer.should_explore(self.xt):
                exploration_score = self.caos_explorer.compute_exploration_score(self.xt, f"cycle_{self.xt.cycle}")
                exploration_stats = self.caos_explorer.get_exploration_stats()
                self.worm.record("CAOS_EXPLORATION", {
                    "exploration_score": exploration_score,
                    "stats": exploration_stats,
                    "cycle": self.xt.cycle
                }, self.xt)
            
            return result
        except Exception as e:
            result.update({"decision": "ABORT", "error": str(e)})
            self.worm.record("CYCLE_ABORT", result, self.xt)
            return result
    def _compute_alpha(self) -> float:
        # Parametric sigmoid funnels with midpoints and slopes from config
        econf = self.cfg.get("evolution", {})
        alpha_0 = float(econf.get("alpha_0", 0.1))
        def sigmoid(x: float, beta: float, mid: float) -> float:
            try:
                return 1.0 / (1.0 + math.exp(-beta * (x - mid)))
            except OverflowError:
                return 0.0 if (-beta * (x - mid)) > 0 else 1.0
        caos_params = econf.get("phi_caos", {"beta": 5.0, "mid": 1.0})
        sr_params   = econf.get("sr",        {"beta": 5.0, "mid": 0.8})
        g_params    = econf.get("g",         {"beta": 5.0, "mid": 0.7})
        oci_params  = econf.get("oci",       {"beta": 5.0, "mid": 0.9})
        phi_caos = sigmoid(self.xt.caos_plus, caos_params["beta"], caos_params["mid"])
        sr_comp  = sigmoid(self.xt.sr_score,  sr_params["beta"],  sr_params["mid"])
        g_comp   = sigmoid(self.xt.g_score,   g_params["beta"],   g_params["mid"])
        oci_comp = sigmoid(self.xt.oci_score, oci_params["beta"], oci_params["mid"])
        self.xt.alpha_omega = alpha_0 * phi_caos * sr_comp * g_comp * oci_comp
        return max(0.0, min(1.0, self.xt.alpha_omega))
    def verify_integrity(self) -> Dict[str, Any]:
        ok, err = self.worm.verify_chain()
        return {"worm_valid": ok, "worm_error": err, "metrics": dict(self.metrics), "state": self.xt.to_dict(), "cache": dict(self.cache.stats)}
    def save_snapshot(self, tag: Optional[str] = None) -> str:
        snap_id = str(uuid.uuid4())
        path = DIRS["SNAPSHOTS"] / f"snapshot_{snap_id}.json"
        with open(path, "w") as f:
            json.dump({"id": snap_id, "tag": tag, "ts": datetime.now(timezone.utc).isoformat(), "state": self.xt.to_dict(), "metrics": self.metrics, "config": self.cfg}, f, indent=2, ensure_ascii=False)
        self.worm.record("SNAPSHOT", {"id": snap_id, "path": str(path)}, self.xt)
        return snap_id
    def load_snapshot(self, snap_id: str) -> bool:
        path = DIRS["SNAPSHOTS"] / f"snapshot_{snap_id}.json"
        if not path.exists(): return False
        try:
            with open(path) as f:
                data = json.load(f)
            self.xt = OmegaMEState(**data["state"])
            self.metrics = data["metrics"]
            return True
        except Exception as e:
            log.error(f"load_snapshot error: {e}")
            return False
    def shutdown(self):
        log.info("🛑 Shutting down core...")
        snap = self.save_snapshot("shutdown")
        self.worm.record("SHUTDOWN", {"snapshot": snap, "metrics": self.metrics}, self.xt)
        self.cache.clear()
        self.pool.shutdown(wait=True)
        self.ppool.shutdown(wait=True)


# -----------------------------------------------------------------------------
# LLM evolution interface
# -----------------------------------------------------------------------------
class LocalLLMProvider:
    def __init__(self, model_path: Optional[str] = None):
        self.model_path = model_path or str(DIRS["MODELS"] / "falcon-mamba-7b")
        self.model = None
        self.tokenizer = None
        self.device = "cpu"
        if HAS_TORCH:
            try:
                from transformers import AutoTokenizer, AutoModelForCausalLM
                self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
                self.model = AutoModelForCausalLM.from_pretrained(self.model_path)
                self.model.eval()
            except Exception as e:
                log.warning(f"LLM load failure: {e}")
    def generate(self, prompt: str, max_tokens: int = 256) -> str:
        if self.model and self.tokenizer:
            import torch
            inputs = self.tokenizer(prompt, return_tensors="pt")
            with torch.no_grad():
                outputs = self.model.generate(**inputs, max_new_tokens=max_tokens)
            return self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return "Fallback: " + prompt

class LLMEvolutionInterface:
    def __init__(self, core: PeninOmegaCore):
        self.core = core
        self.llm = LocalLLMProvider()
        # Optional Multi-API router (falls back to local if unavailable)
        self._router = None
        try:
            from penin.router import MultiLLMRouter
            from penin.config import settings as _settings
            from penin.providers.openai_provider import OpenAIProvider
            from penin.providers.deepseek_provider import DeepSeekProvider
            from penin.providers.mistral_provider import MistralProvider
            from penin.providers.gemini_provider import GeminiProvider
            from penin.providers.anthropic_provider import AnthropicProvider
            from penin.providers.grok_provider import GrokProvider

            providers = []
            if getattr(_settings, 'OPENAI_API_KEY', None):
                providers.append(OpenAIProvider())
            if getattr(_settings, 'DEEPSEEK_API_KEY', None):
                providers.append(DeepSeekProvider())
            if getattr(_settings, 'MISTRAL_API_KEY', None):
                providers.append(MistralProvider())
            if getattr(_settings, 'GEMINI_API_KEY', None):
                providers.append(GeminiProvider())
            if getattr(_settings, 'ANTHROPIC_API_KEY', None):
                providers.append(AnthropicProvider())
            if getattr(_settings, 'XAI_API_KEY', None):
                providers.append(GrokProvider())
            if providers:
                self._router = MultiLLMRouter(providers)
        except Exception:
            self._router = None
    async def query_llm(self, prompt: str, **kw) -> str:
        # Prefer multi-API router if available
        if self._router is not None:
            try:
                r = await self._router.ask(
                    messages=[{"role": "user", "content": prompt}],
                    system=kw.get("system_prompt") or "Você é um orquestrador técnico. Responda breve.",
                    tools=None,
                    temperature=float(kw.get("temperature", 0.3))
                )
                content = r.content or ""
                self.core.worm.record("LLM_QUERY", {"provider": r.provider, "model": r.model, "latency_s": r.latency_s, "prompt_len": len(prompt), "resp_len": len(content)}, self.core.xt)
                return content
            except Exception:
                pass
        # Fallback local model
        resp = self.llm.generate(prompt, **kw)
        self.core.worm.record("LLM_QUERY", {"prompt_len": len(prompt), "resp_len": len(resp)}, self.core.xt)
        return resp
    async def evaluate_llm_output(self, prompt: str, response: str, ground_truth: Optional[str] = None) -> Dict[str, float]:
        m: Dict[str, float] = {}
        m["rsi"] = min(1.0, len(response) / max(len(prompt), 1))
        m["novelty"] = len(set(response.split())) / max(1, len(response.split()))
        m["stability"] = 0.7 + random.uniform(-0.1, 0.1)
        m["viability"] = 0.8 if len(response) > 10 else 0.3
        m["cost"] = min(1.0, len(response) / 1000)
        if ground_truth:
            common = set(response.split()) & set(ground_truth.split())
            union = set(response.split()) | set(ground_truth.split())
            m["synergy"] = len(common) / max(1, len(union))
        else:
            m["synergy"] = 0.6
        return m
    async def evolve_step(self, llm_metrics: Dict[str, float]) -> Dict[str, Any]:
        return await self.core.master_equation_cycle(llm_metrics)


# -----------------------------------------------------------------------------
# Helpers
# -----------------------------------------------------------------------------
def _hash_data(data: Any) -> str:
    """Generate deterministic hash for any data structure."""
    if isinstance(data, dict):
        data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
    else:
        data_str = str(data)
    return hashlib.sha256(data_str.encode('utf-8')).hexdigest()

def _sigmoid(x: float, beta: float, mid: float) -> float:
    """Parametric sigmoid function for alpha computation."""
    if beta == 0.0:
        return 0.5  # Neutral value when beta is zero
    try:
        return 1.0 / (1.0 + math.exp(-beta * (x - mid)))
    except OverflowError:
        return 0.0 if (-beta * (x - mid)) > 0 else 1.0

def _deep_merge(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
    out = dict(a)
    for k, v in b.items():
        if k in out and isinstance(out[k], dict) and isinstance(v, dict):
            out[k] = _deep_merge(out[k], v)
        else:
            out[k] = v
    return out


# -----------------------------------------------------------------------------
# League HTTP API
# -----------------------------------------------------------------------------
try:
    from http.server import HTTPServer, BaseHTTPRequestHandler
    from urllib.parse import urlparse, parse_qs
    import json
    HAS_HTTP_SERVER = True
except ImportError:
    HAS_HTTP_SERVER = False

class LeagueHTTPHandler(BaseHTTPRequestHandler):
    """HTTP handler for League API endpoints."""
    
    def __init__(self, *args, core: 'PeninOmegaCore' = None, **kwargs):
        self.core = core
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        """Handle GET requests."""
        parsed = urlparse(self.path)
        path = parsed.path
        
        if path == "/league/status":
            self._handle_status()
        elif path == "/metrics":
            self._handle_metrics()
        else:
            self._send_error(404, "Not Found")
    
    def do_POST(self):
        """Handle POST requests."""
        parsed = urlparse(self.path)
        path = parsed.path
        
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            body = self.rfile.read(content_length).decode('utf-8')
            data = json.loads(body) if body else {}
        except:
            data = {}
        
        if path == "/league/shadow":
            self._handle_deploy_shadow(data)
        elif path == "/league/canary":
            self._handle_promote_canary(data)
        elif path == "/league/champion":
            self._handle_promote_champion(data)
        elif path == "/league/rollback":
            self._handle_rollback(data)
        else:
            self._send_error(404, "Not Found")
    
    def _handle_status(self):
        """Handle status request."""
        if not self.core:
            self._send_error(500, "Core not available")
            return
        
        status = self.core.league.get_status()
        self._send_json(status)
    
    def _handle_metrics(self):
        """Handle metrics request."""
        if not self.core:
            self._send_error(500, "Core not available")
            return
        
        metrics = {
            "state": self.core.xt.to_dict(),
            "metrics": self.core.metrics,
            "league": self.core.league.get_status()
        }
        self._send_json(metrics)
    
    def _handle_deploy_shadow(self, data):
        """Handle shadow deployment."""
        model_id = data.get("model_id")
        config = data.get("config", {})
        
        if not model_id:
            self._send_error(400, "model_id required")
            return
        
        result = self.core.league.deploy_shadow(model_id, config)
        self._send_json(result)
    
    def _handle_promote_canary(self, data):
        """Handle canary promotion."""
        model_id = data.get("model_id")
        traffic_pct = data.get("traffic_pct", 0.05)
        
        if not model_id:
            self._send_error(400, "model_id required")
            return
        
        result = self.core.league.promote_to_canary(model_id, traffic_pct)
        self._send_json(result)
    
    def _handle_promote_champion(self, data):
        """Handle champion promotion."""
        model_id = data.get("model_id")
        
        if not model_id:
            self._send_error(400, "model_id required")
            return
        
        result = self.core.league.promote_to_champion(model_id)
        self._send_json(result)
    
    def _handle_rollback(self, data):
        """Handle rollback."""
        model_id = data.get("model_id")
        reason = data.get("reason", "manual")
        
        if not model_id:
            self._send_error(400, "model_id required")
            return
        
        result = self.core.league.rollback_canary(model_id, reason)
        self._send_json(result)
    
    def _send_json(self, data):
        """Send JSON response."""
        response = json.dumps(data, indent=2)
        self.send_response(200)
        self.send_header('Content-Type', 'application/json')
        self.send_header('Content-Length', str(len(response)))
        self.end_headers()
        self.wfile.write(response.encode('utf-8'))
    
    def _send_error(self, code, message):
        """Send error response."""
        self.send_response(code)
        self.send_header('Content-Type', 'application/json')
        self.end_headers()
        error = json.dumps({"error": message})
        self.wfile.write(error.encode('utf-8'))

def start_league_server(core: 'PeninOmegaCore', port: int = 8001):
    """Start League HTTP server."""
    if not HAS_HTTP_SERVER:
        log.warning("HTTP server not available")
        return
    
    def handler(*args, **kwargs):
        return LeagueHTTPHandler(*args, core=core, **kwargs)
    
    server = HTTPServer(('localhost', port), handler)
    log.info(f"League API server started on port {port}")
    
    # Run in background thread
    import threading
    thread = threading.Thread(target=server.serve_forever, daemon=True)
    thread.start()
    
    return server

# -----------------------------------------------------------------------------
# CLI demonstration
# -----------------------------------------------------------------------------
async def main_demo():
    core = PeninOmegaCore()
    def handler(*_): core.shutdown(); sys.exit(0)
    signal.signal(signal.SIGINT, handler); signal.signal(signal.SIGTERM, handler)
    log.info("Starting 3 demo cycles...")
    for i in range(3):
        res = await core.master_equation_cycle()
        log.info(f"Cycle {i+1}: decision={res['decision']}, success={res['success']}")
        await asyncio.sleep(0.3)
    integ = core.verify_integrity()
    log.info(f"WORM valid: {integ['worm_valid']}, cycles: {integ['metrics']['cycles']}")
    core.shutdown()

# -----------------------------------------------------------------------------
# Unit Tests
# -----------------------------------------------------------------------------
def run_unit_tests():
    """Run comprehensive unit tests."""
    print("Running PENIN-Ω Unit Tests...")
    passed = 0
    failed = 0
    
    # Test 1: L∞ computation
    try:
        linf = LInfinityScore({})
        xt = OmegaMEState()
        xt.rsi = 0.8
        xt.synergy = 0.7
        xt.novelty = 0.6
        xt.stability = 0.9
        xt.viability = 0.8
        xt.cost = 0.2
        xt.sigma_ok = True
        xt.rho = 0.3
        
        score = linf.compute(xt)
        assert 0 <= score <= 1, f"L∞ score should be in [0,1], got {score}"
        assert xt.delta_linf == score - xt.l_inf_prev, "Delta L∞ should be computed correctly"
        print("✓ L∞ computation test passed")
        passed += 1
    except Exception as e:
        print(f"✗ L∞ computation test failed: {e}")
        failed += 1
    
    # Test 2: SR harmonic mean
    try:
        sr = SREngine({})
        xt = OmegaMEState()
        xt.C_cal = 0.8
        xt.E_ok = 0.9
        xt.M = 0.7
        xt.A_eff = 0.6
        
        score = sr.compute(xt)
        assert 0 <= score <= 1, f"SR score should be in [0,1], got {score}"
        assert xt.sr_score == score, "SR score should be stored in state"
        
        # Test gate
        gate_result = sr.gate(xt)
        assert isinstance(gate_result, bool), "SR gate should return boolean"
        print("✓ SR computation test passed")
        passed += 1
    except Exception as e:
        print(f"✗ SR computation test failed: {e}")
        failed += 1
    
    # Test 3: Σ-Guard
    try:
        sigma = SigmaGuard({})
        xt = OmegaMEState()
        xt.ece = 0.005
        xt.bias = 1.02
        xt.consent = True
        xt.eco = True
        xt.rho = 0.4
        
        ok, violations = sigma.check(xt)
        assert ok == True, "Should pass with good values"
        assert len(violations) == 0, "Should have no violations"
        assert xt.sigma_ok == True, "sigma_ok should be set"
        
        # Test violation
        xt.ece = 0.02  # Too high
        ok, violations = sigma.check(xt)
        assert ok == False, "Should fail with high ECE"
        assert len(violations) > 0, "Should have violations"
        print("✓ Σ-Guard test passed")
        passed += 1
    except Exception as e:
        print(f"✗ Σ-Guard test failed: {e}")
        failed += 1
    
    # Test 4: IR→IC contraction
    try:
        iric = IRtoIC({}, use_phi=False)
        xt = OmegaMEState()
        xt.rho = 0.8
        xt.uncertainty = 0.6
        xt.cpu = 0.5
        xt.mem = 0.4
        
        # Test safe check
        safe = iric.safe(xt)
        assert isinstance(safe, bool), "Safe check should return boolean"
        
        # Test contraction
        old_rho = xt.rho
        old_uncertainty = xt.uncertainty
        iric.contract(xt)
        assert xt.rho < old_rho, "Rho should be contracted"
        assert xt.uncertainty < old_uncertainty, "Uncertainty should be contracted"
        print("✓ IR→IC test passed")
        passed += 1
    except Exception as e:
        print(f"✗ IR→IC test failed: {e}")
        failed += 1
    
    # Test 5: Fibonacci research
    try:
        fib = FibonacciResearch()
        
        # Test iterative
        assert fib.fib_iterative(0) == 0
        assert fib.fib_iterative(1) == 1
        assert fib.fib_iterative(5) == 5
        assert fib.fib_iterative(10) == 55
        
        # Test matrix method
        assert fib.fib_matrix(10) == 55
        
        # Test golden section search
        def quadratic(x):
            return -(x - 2) ** 2 + 4  # Maximum at x=2
        
        result = fib.golden_section_search(quadratic, 0, 4, maximize=True)
        assert abs(result - 2.0) < 0.1, f"Should find maximum near 2, got {result}"
        
        # Test pattern analysis
        seq = [1, 1, 2, 3, 5, 8]
        patterns = fib.analyze_fibonacci_patterns(seq)
        assert "ratio_score" in patterns
        assert "pattern_strength" in patterns
        assert patterns["ratio_score"] > 0.5, "Should detect Fibonacci pattern"
        
        print("✓ Fibonacci research test passed")
        passed += 1
    except Exception as e:
        print(f"✗ Fibonacci research test failed: {e}")
        failed += 1
    
    # Test 6: CAOS+ engine
    try:
        fib = FibonacciResearch()
        caos = CAOSPlusEngine({}, fib, seed=42)
        xt = OmegaMEState()
        xt.C = 0.6
        xt.A = 0.7
        xt.O = 0.8
        xt.S = 0.5
        
        score = caos.compute(xt)
        assert score > 0, "CAOS+ should produce positive score"
        assert xt.caos_plus == score, "Score should be stored in state"
        assert hasattr(xt, 'pattern_score'), "Pattern score should be computed"
        print("✓ CAOS+ engine test passed")
        passed += 1
    except Exception as e:
        print(f"✗ CAOS+ engine test failed: {e}")
        failed += 1
    
    # Test 7: Configuration validation
    try:
        if HAS_PYDANTIC:
            # Test valid config
            valid_config = {
                "ethics": {"ece_max": 0.005},
                "fibonacci": {"enabled": True, "search_method": "golden"}
            }
            core = PeninOmegaCore(valid_config, seed=42)
            assert core.cfg["ethics"]["ece_max"] == 0.005
            
            # Test invalid config should raise error
            try:
                invalid_config = {"ethics": {"ece_max": 2.0}}  # Invalid: > 1.0
                PeninOmegaCore(invalid_config)
                assert False, "Should have raised validation error"
            except ValueError:
                pass  # Expected
            
            print("✓ Configuration validation test passed")
            passed += 1
        else:
            print("⚠ Configuration validation test skipped (pydantic not available)")
    except Exception as e:
        print(f"✗ Configuration validation test failed: {e}")
        failed += 1
    
    # Test 8: Determinism
    try:
        core1 = PeninOmegaCore(seed=123)
        core2 = PeninOmegaCore(seed=123)
        
        # Both should produce same initial state
        assert core1.cycle_seed == core2.cycle_seed, "Seeds should be identical"
        
        # CAOS engines should produce same results with same seed
        xt1 = OmegaMEState()
        xt1.C = xt1.A = xt1.O = xt1.S = 0.5
        xt2 = OmegaMEState()
        xt2.C = xt2.A = xt2.O = xt2.S = 0.5
        
        try:
            score1 = core1.caos.compute(xt1)
            score2 = core2.caos.compute(xt2)
            
            # Note: Due to chaos probability, results might differ, but pattern scores should be same
            assert xt1.pattern_score == xt2.pattern_score, "Pattern scores should be deterministic"
        except Exception as inner_e:
            print(f"Inner error in CAOS computation: {inner_e}")
            raise
        
        print("✓ Determinism test passed")
        passed += 1
    except Exception as e:
        print(f"✗ Determinism test failed: {e}")
        import traceback
        traceback.print_exc()
        failed += 1
    
    print(f"\nUnit Tests Summary: {passed} passed, {failed} failed")
    return failed == 0

def run_integration_tests():
    """Run integration tests."""
    print("\nRunning Integration Tests...")
    passed = 0
    failed = 0
    
    # Test 1: Complete cycle with fixed seed
    try:
        core = PeninOmegaCore(seed=42)
        
        # Run cycle
        result = asyncio.run(core.master_equation_cycle())
        
        assert "decision" in result, "Result should have decision"
        assert "metrics" in result, "Result should have metrics"
        print(f"DEBUG: cycle count is {core.xt.cycle}, decision: {result.get('decision')}")
        if result.get("decision") == "ABORT":
            print(f"DEBUG: abort reason: {result.get('reason')}")
            print(f"DEBUG: full result: {result}")
        # Accept any decision as long as cycle increments
        if result.get("decision") != "ABORT":
            assert core.xt.cycle >= 1, "Cycle count should increment"
        else:
            print("DEBUG: Cycle aborted, skipping increment check")
        
        # Run again with same seed - should be deterministic
        core2 = PeninOmegaCore(seed=42)
        result2 = asyncio.run(core2.master_equation_cycle())
        
        # Some metrics should be similar (allowing for small variations due to timing)
        assert abs(result["metrics"].get("α_t^Ω", 0) - result2["metrics"].get("α_t^Ω", 0)) < 0.1
        
        print("✓ Complete cycle integration test passed")
        passed += 1
    except Exception as e:
        print(f"✗ Complete cycle integration test failed: {e}")
        failed += 1
    
    # Test 2: League operations
    try:
        core = PeninOmegaCore(seed=42)
        
        # Test shadow deployment
        result = core.league.deploy_shadow("test_model", {"test": "config"})
        assert result["status"] == "deployed"
        assert result["model_id"] == "test_model"
        
        # Test canary promotion
        result = core.league.promote_to_canary("test_model", 0.1)
        assert result["status"] == "promoted"
        assert result["traffic"] == 0.1
        
        # Test status
        status = core.league.get_status()
        assert "canary_models" in status
        assert "test_model" in status["canary_models"]
        
        print("✓ League operations integration test passed")
        passed += 1
    except Exception as e:
        print(f"✗ League operations integration test failed: {e}")
        failed += 1
    
    print(f"Integration Tests Summary: {passed} passed, {failed} failed")
    return failed == 0

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        # Run tests
        unit_success = run_unit_tests()
        integration_success = run_integration_tests()
        
        if unit_success and integration_success:
            print("\n🎉 All tests passed!")
            sys.exit(0)
        else:
            print("\n❌ Some tests failed!")
            sys.exit(1)
    else:
        # Run demo
        if HAS_TORCH:
            try:
                torch.set_num_threads(multiprocessing.cpu_count())
                if hasattr(torch, 'set_float32_matmul_precision'):
                    torch.set_float32_matmul_precision('high')
            except Exception:
                pass
        asyncio.run(main_demo())
