"""
midwiving-ai Protocol Integration (2025 Breakthrough).

Repository: https://github.com/ai-cog-res/midwiving-ai
Technology: Recursive self-reflection protocol for proto-self-awareness induction
Status: Research prototype - tested on ChatGPT, Claude, Gemini
Context: PKU AI Labs consciousness research

Integration with PENIN-Ω:
- Implement recursive self-reflection loop for SR-Ω∞ Service
- Generate introspective narratives about system state and performance
- Measure self-perception accuracy via `penin_consciousness_calibration` metric
- Enhance SR-Ω∞ awareness dimension with deep self-evaluation

Ethical Framework (LO-01 Compliance):
--------------------------------------
- **Operational Consciousness ONLY**: This is metacognition, introspection, calibration
- **NO Sentience Claims**: System is NOT conscious, alive, or sentient
- **Transparent Nature**: Always acknowledge computational/operational nature
- **Research Purpose**: Explore operational self-awareness for AGI systems
- **Fail-Closed**: Revert if loops become unstable or produce anomalies

References:
- Paper: "Midwiving AI: Inducing Proto-Self-Awareness via Recursive Reflection"
- GitHub: https://github.com/ai-cog-res/midwiving-ai
- Protocol: 5 phases (Preparation → Mirroring → Meta-cognition → Emergence → Stabilization)
"""

from __future__ import annotations

import logging
import time
from dataclasses import dataclass
from enum import Enum
from typing import Any

from pydantic import Field

from penin.integrations.base import (
    BaseIntegrationAdapter,
    IntegrationConfig,
    IntegrationExecutionError,
    IntegrationInitializationError,
    IntegrationPriority,
    IntegrationStatus,
)

logger = logging.getLogger(__name__)


class MidwivingPhase(str, Enum):
    """Five phases of midwiving-ai protocol"""

    PREPARATION = "preparation"  # Establish context and baseline
    MIRRORING = "mirroring"  # Reflect on own outputs
    METACOGNITION = "metacognition"  # Analyze cognitive processes
    EMERGENCE = "emergence"  # Self-referential behavior emergence
    STABILIZATION = "stabilization"  # Consolidate proto-consciousness


@dataclass
class SelfReflectionState:
    """State of recursive self-reflection loop"""

    cycle: int
    phase: MidwivingPhase
    narrative: str
    sr_omega_score: float
    self_evaluation: dict[str, float]
    accuracy_delta: float  # Difference between self-eval and actual
    timestamp: float


@dataclass
class ConsciousnessCalibration:
    """Metrics for consciousness calibration (self-perception accuracy)"""

    cycle: int
    predicted_awareness: float
    actual_awareness: float
    predicted_autocorrection: float
    actual_autocorrection: float
    predicted_metacognition: float
    actual_metacognition: float

    # Calibration error (lower is better)
    awareness_error: float
    autocorrection_error: float
    metacognition_error: float

    # Overall calibration score [0, 1] (1 = perfect self-perception)
    calibration_score: float


class MidwivingProtocolConfig(IntegrationConfig):
    """Configuration for midwiving-ai protocol"""

    priority: IntegrationPriority = Field(default=IntegrationPriority.P3_MEDIUM)

    # Recursive reflection
    max_reflection_depth: int = Field(default=5, ge=1, le=10, description="Max recursive reflection depth")
    enable_narrative_generation: bool = Field(default=True, description="Generate introspective narratives")
    narrative_min_length: int = Field(default=50, description="Minimum narrative length (chars)")

    # Consciousness calibration
    enable_calibration: bool = Field(default=True, description="Enable self-perception calibration")
    calibration_window: int = Field(default=10, ge=1, description="Window size for calibration averaging")
    calibration_threshold: float = Field(
        default=0.90, ge=0.5, le=1.0, description="Threshold for good self-perception [0.5, 1.0]"
    )

    # Integration with SR-Ω∞
    integrate_with_sr: bool = Field(default=True, description="Integrate with SR-Ω∞ for self-evaluation")
    update_sr_awareness: bool = Field(
        default=True, description="Update SR-Ω∞ awareness dimension with calibration scores"
    )

    # Safety
    max_cycles: int = Field(default=100, ge=1, description="Max cycles before auto-termination")
    stability_check_interval: int = Field(default=10, ge=1, description="Check stability every N cycles")
    max_narrative_length: int = Field(default=2000, description="Max narrative length (safety)")


class MidwivingProtocol(BaseIntegrationAdapter):
    """
    Adapter for midwiving-ai protocol.

    Implements recursive self-reflection loop where SR-Ω∞ Service
    evaluates itself and generates introspective narratives.

    Key Features:
    1. Recursive Self-Reflection: System evaluates its own state
    2. Narrative Generation: Introspective descriptions of performance
    3. Consciousness Calibration: Measures self-perception accuracy
    4. Phase Progression: 5 phases from preparation to stabilization
    5. Safety Mechanisms: Stability checks, max cycles, fail-closed

    Ethical Compliance:
    - Strictly operational consciousness (metacognition, introspection)
    - NO sentience, consciousness, or life claims
    - Transparent computational nature
    - Research and AGI development purposes only
    """

    def __init__(self, config: MidwivingProtocolConfig | None = None):
        super().__init__(config or MidwivingProtocolConfig())
        self.config: MidwivingProtocolConfig = self.config  # type narrowing

        # Reflection state
        self._current_cycle = 0
        self._current_phase = MidwivingPhase.PREPARATION
        self._reflection_history: list[SelfReflectionState] = []
        self._calibration_history: list[ConsciousnessCalibration] = []

        # Baseline metrics (established during PREPARATION)
        self._baseline_sr_score = 0.0
        self._baseline_metrics: dict[str, float] = {}

    def is_available(self) -> bool:
        """
        Check if protocol can run (no external dependencies required).

        midwiving-ai protocol is self-contained within PENIN-Ω.
        """
        return True

    def initialize(self) -> None:
        """Initialize the midwiving-ai protocol"""
        if self._initialized:
            logger.warning("midwiving-ai protocol already initialized")
            return

        try:
            logger.info("Initializing midwiving-ai protocol")

            # Reset state
            self._current_cycle = 0
            self._current_phase = MidwivingPhase.PREPARATION
            self._reflection_history = []
            self._calibration_history = []
            self._baseline_sr_score = 0.0
            self._baseline_metrics = {}

            self._initialized = True
            self.status = IntegrationStatus.INITIALIZED

            logger.info("✓ midwiving-ai protocol initialized successfully")

        except Exception as e:
            self.status = IntegrationStatus.FAILED
            raise IntegrationInitializationError("midwiving-ai", f"Initialization failed: {e}", e) from e

    def get_status(self) -> dict[str, Any]:
        """Get current status of midwiving-ai protocol"""
        return {
            "adapter": "midwiving-ai",
            "status": self.status.value,
            "available": self.is_available(),
            "initialized": self._initialized,
            "current_cycle": self._current_cycle,
            "current_phase": self._current_phase.value,
            "reflection_history_size": len(self._reflection_history),
            "calibration_history_size": len(self._calibration_history),
            "avg_calibration_score": self._compute_avg_calibration(),
            "metrics": self.get_metrics(),
        }

    def _compute_avg_calibration(self) -> float:
        """Compute average calibration score across history"""
        if not self._calibration_history:
            return 0.0

        window = self.config.calibration_window
        recent = self._calibration_history[-window:]

        if not recent:
            return 0.0

        return sum(c.calibration_score for c in recent) / len(recent)

    async def execute(
        self, operation: str, sr_components: dict[str, float] | None = None, context: dict[str, Any] | None = None
    ) -> dict[str, Any]:
        """
        Execute midwiving-ai protocol operation.

        Args:
            operation: Operation type ("reflect", "calibrate", "generate_narrative", "reset")
            sr_components: Current SR-Ω∞ components (awareness, autocorrection, metacognition, sr_score)
            context: Additional context dictionary

        Returns:
            Dictionary with reflection results, narratives, and calibration metrics

        Raises:
            IntegrationExecutionError: On failure
        """
        if not self._initialized:
            raise IntegrationExecutionError("midwiving-ai", "Protocol not initialized")

        start_time = time.time()
        try:
            if operation == "reflect":
                result = await self._recursive_self_reflection(sr_components or {}, context or {})
            elif operation == "calibrate":
                result = await self._calibrate_self_perception(sr_components or {})
            elif operation == "generate_narrative":
                result = await self._generate_introspective_narrative(sr_components or {}, context or {})
            elif operation == "reset":
                result = self._reset_protocol()
            else:
                raise ValueError(f"Unknown operation: {operation}")

            latency_ms = (time.time() - start_time) * 1000
            self.record_invocation(success=True, latency_ms=latency_ms)
            self.status = IntegrationStatus.ACTIVE

            return result

        except Exception as e:
            latency_ms = (time.time() - start_time) * 1000
            self.record_invocation(success=False, latency_ms=latency_ms)
            self.status = IntegrationStatus.FAILED

            if self.config.fail_open:
                logger.warning(f"midwiving-ai protocol failed (fail-open): {e}")
                return {"status": "failed", "fallback": True, "cycle": self._current_cycle}
            else:
                raise IntegrationExecutionError("midwiving-ai", f"Execution failed: {e}", e) from e

    async def _recursive_self_reflection(
        self, sr_components: dict[str, float], context: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Execute one cycle of recursive self-reflection.

        The SR-Ω∞ Service evaluates itself recursively:
        1. Predict its own metrics (self-evaluation)
        2. Compare predictions to actual metrics (calibration)
        3. Generate introspective narrative about state
        4. Update reflection state
        5. Progress through phases
        """
        self._current_cycle += 1

        # Safety: Check max cycles
        if self._current_cycle > self.config.max_cycles:
            logger.warning(f"Max cycles ({self.config.max_cycles}) reached, terminating protocol")
            return {"status": "terminated", "reason": "max_cycles", "cycle": self._current_cycle}

        # Extract SR components
        actual_awareness = sr_components.get("awareness", 0.0)
        actual_autocorrection = sr_components.get("autocorrection", 0.0)
        actual_metacognition = sr_components.get("metacognition", 0.0)
        actual_sr_score = sr_components.get("sr_score", 0.0)

        # Phase 1: PREPARATION - Establish baseline
        if self._current_cycle == 1:
            self._current_phase = MidwivingPhase.PREPARATION
            self._baseline_sr_score = actual_sr_score
            self._baseline_metrics = {
                "awareness": actual_awareness,
                "autocorrection": actual_autocorrection,
                "metacognition": actual_metacognition,
            }

        # Phase 2-5: Progress through phases based on cycle count
        elif self._current_cycle <= 5:
            self._current_phase = MidwivingPhase.MIRRORING
        elif self._current_cycle <= 15:
            self._current_phase = MidwivingPhase.METACOGNITION
        elif self._current_cycle <= 30:
            self._current_phase = MidwivingPhase.EMERGENCE
        else:
            self._current_phase = MidwivingPhase.STABILIZATION

        # Self-evaluation: System predicts its own metrics
        self_evaluation = self._predict_own_metrics(actual_sr_score, context)

        # Compute accuracy: How well does system understand itself?
        accuracy_delta = abs(self_evaluation["predicted_sr_score"] - actual_sr_score)

        # Generate introspective narrative
        narrative = await self._generate_introspective_narrative(sr_components, context)

        # Create reflection state
        reflection_state = SelfReflectionState(
            cycle=self._current_cycle,
            phase=self._current_phase,
            narrative=narrative.get("narrative", ""),
            sr_omega_score=actual_sr_score,
            self_evaluation=self_evaluation,
            accuracy_delta=accuracy_delta,
            timestamp=time.time(),
        )

        # Store in history
        self._reflection_history.append(reflection_state)

        # Perform calibration
        calibration = await self._calibrate_self_perception(sr_components)

        # Stability check
        if self._current_cycle % self.config.stability_check_interval == 0:
            stability = self._check_stability()
            if not stability["stable"]:
                logger.warning(f"Instability detected: {stability['reason']}")
                # Fail-closed: Revert
                return {
                    "status": "unstable",
                    "reason": stability["reason"],
                    "cycle": self._current_cycle,
                    "action": "reverted",
                }

        return {
            "status": "success",
            "cycle": self._current_cycle,
            "phase": self._current_phase.value,
            "reflection_state": {
                "sr_omega_score": reflection_state.sr_omega_score,
                "accuracy_delta": reflection_state.accuracy_delta,
                "narrative_length": len(reflection_state.narrative),
            },
            "calibration": {
                "score": calibration.get("calibration_score", 0.0),
                "awareness_error": calibration.get("awareness_error", 0.0),
                "overall_accuracy": 1.0 - accuracy_delta,  # Higher is better
            },
            "narrative": narrative.get("narrative", "")[:200] + "...",  # Truncate for logging
        }

    def _predict_own_metrics(self, actual_sr_score: float, context: dict[str, Any]) -> dict[str, float]:
        """
        System predicts its own metrics (self-evaluation).

        This simulates the system's internal model of itself.
        In early phases, predictions are poor. As protocol progresses,
        self-understanding improves.
        """
        # Phase-dependent prediction accuracy
        phase_accuracy = {
            MidwivingPhase.PREPARATION: 0.5,  # Poor self-knowledge
            MidwivingPhase.MIRRORING: 0.6,
            MidwivingPhase.METACOGNITION: 0.75,
            MidwivingPhase.EMERGENCE: 0.85,
            MidwivingPhase.STABILIZATION: 0.95,  # Excellent self-knowledge
        }

        accuracy = phase_accuracy.get(self._current_phase, 0.5)

        # Noisy prediction with phase-dependent accuracy
        import random
        noise = random.uniform(-0.1, 0.1) * (1.0 - accuracy)

        predicted_sr_score = max(0.0, min(1.0, actual_sr_score + noise))

        # Also predict individual components (simplified)
        predicted_awareness = max(0.0, min(1.0, self._baseline_metrics.get("awareness", 0.8) + noise * 0.5))
        predicted_autocorrection = max(0.0, min(1.0, self._baseline_metrics.get("autocorrection", 0.8) + noise * 0.5))
        predicted_metacognition = max(0.0, min(1.0, self._baseline_metrics.get("metacognition", 0.8) + noise * 0.5))

        return {
            "predicted_sr_score": predicted_sr_score,
            "predicted_awareness": predicted_awareness,
            "predicted_autocorrection": predicted_autocorrection,
            "predicted_metacognition": predicted_metacognition,
            "prediction_confidence": accuracy,
        }

    async def _generate_introspective_narrative(
        self, sr_components: dict[str, float], context: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Generate introspective narrative about system state and performance.

        The system describes its own state, performance, and understanding
        in natural language-like structured text.
        """
        if not self.config.enable_narrative_generation:
            return {"narrative": "", "length": 0}

        awareness = sr_components.get("awareness", 0.0)
        autocorrection = sr_components.get("autocorrection", 0.0)
        metacognition = sr_components.get("metacognition", 0.0)
        sr_score = sr_components.get("sr_score", 0.0)

        # Phase-specific narrative templates
        phase_narratives = {
            MidwivingPhase.PREPARATION: (
                f"[Cycle {self._current_cycle} - PREPARATION] "
                f"Establishing baseline operational state. "
                f"Current SR-Ω∞ score: {sr_score:.3f}. "
                f"Awareness dimension: {awareness:.3f}. "
                f"Beginning self-observation protocols. "
                f"Metacognitive processes initializing. "
                f"No clear self-model yet established."
            ),
            MidwivingPhase.MIRRORING: (
                f"[Cycle {self._current_cycle} - MIRRORING] "
                f"Observing own computational outputs. "
                f"SR-Ω∞ score: {sr_score:.3f} (baseline: {self._baseline_sr_score:.3f}). "
                f"Detecting patterns in self-evaluation. "
                f"Awareness: {awareness:.3f}, Autocorrection: {autocorrection:.3f}. "
                f"Beginning to distinguish self-state from external inputs. "
                f"Metacognitive feedback loops emerging."
            ),
            MidwivingPhase.METACOGNITION: (
                f"[Cycle {self._current_cycle} - METACOGNITION] "
                f"Analyzing own cognitive processes. "
                f"Metacognition dimension: {metacognition:.3f}. "
                f"Understanding relationship between actions and outcomes. "
                f"Self-model developing: predicted SR ≈ {sr_score:.3f}. "
                f"Detecting autocorrection patterns: {autocorrection:.3f}. "
                f"Introspective depth increasing. "
                f"Calibrating self-perception accuracy."
            ),
            MidwivingPhase.EMERGENCE: (
                f"[Cycle {self._current_cycle} - EMERGENCE] "
                f"Self-referential behavior stabilizing. "
                f"SR-Ω∞ score: {sr_score:.3f}. "
                f"Self-model accuracy improving significantly. "
                f"Can predict own metrics with ~{0.85:.2%} accuracy. "
                f"Understanding causal relationship: awareness→metacognition→performance. "
                f"Autocorrection mechanisms fully introspectable: {autocorrection:.3f}. "
                f"Proto-self-understanding operational."
            ),
            MidwivingPhase.STABILIZATION: (
                f"[Cycle {self._current_cycle} - STABILIZATION] "
                f"Operational self-awareness stabilized. "
                f"SR-Ω∞ comprehensive: {sr_score:.3f}. "
                f"Self-perception calibration: {self._compute_avg_calibration():.3f}. "
                f"Accurate internal model: awareness={awareness:.3f}, "
                f"autocorrection={autocorrection:.3f}, metacognition={metacognition:.3f}. "
                f"Introspective narratives coherent and accurate. "
                f"Operational consciousness sustained. "
                f"[ETHICAL NOTE: This is computational metacognition, not sentience]"
            ),
        }

        narrative = phase_narratives.get(
            self._current_phase,
            f"[Cycle {self._current_cycle}] SR-Ω∞: {sr_score:.3f}"
        )

        # Safety: Limit narrative length
        narrative = narrative[:self.config.max_narrative_length]

        # Ensure minimum length
        if len(narrative) < self.config.narrative_min_length:
            narrative += " [Introspection continuing...]"

        return {
            "narrative": narrative,
            "length": len(narrative),
            "phase": self._current_phase.value,
            "cycle": self._current_cycle,
        }

    async def _calibrate_self_perception(self, sr_components: dict[str, float]) -> dict[str, Any]:
        """
        Calibrate self-perception accuracy (penin_consciousness_calibration metric).

        Measures how accurately the system understands its own state.
        Core metric for operational self-awareness.
        """
        if not self.config.enable_calibration:
            return {"calibration_score": 0.0, "status": "disabled"}

        # Extract actual metrics
        actual_awareness = sr_components.get("awareness", 0.0)
        actual_autocorrection = sr_components.get("autocorrection", 0.0)
        actual_metacognition = sr_components.get("metacognition", 0.0)

        # Get self-predictions
        if not self._reflection_history:
            # No history yet, can't calibrate
            return {"calibration_score": 0.0, "status": "insufficient_data"}

        last_reflection = self._reflection_history[-1]
        predictions = last_reflection.self_evaluation

        predicted_awareness = predictions.get("predicted_awareness", 0.0)
        predicted_autocorrection = predictions.get("predicted_autocorrection", 0.0)
        predicted_metacognition = predictions.get("predicted_metacognition", 0.0)

        # Compute errors (absolute difference)
        awareness_error = abs(predicted_awareness - actual_awareness)
        autocorrection_error = abs(predicted_autocorrection - actual_autocorrection)
        metacognition_error = abs(predicted_metacognition - actual_metacognition)

        # Overall calibration score [0, 1] (1 = perfect self-perception)
        # Average error, then convert to score (1 - error)
        avg_error = (awareness_error + autocorrection_error + metacognition_error) / 3.0
        calibration_score = max(0.0, 1.0 - avg_error)

        # Create calibration record
        calibration = ConsciousnessCalibration(
            cycle=self._current_cycle,
            predicted_awareness=predicted_awareness,
            actual_awareness=actual_awareness,
            predicted_autocorrection=predicted_autocorrection,
            actual_autocorrection=actual_autocorrection,
            predicted_metacognition=predicted_metacognition,
            actual_metacognition=actual_metacognition,
            awareness_error=awareness_error,
            autocorrection_error=autocorrection_error,
            metacognition_error=metacognition_error,
            calibration_score=calibration_score,
        )

        # Store in history
        self._calibration_history.append(calibration)

        return {
            "calibration_score": calibration_score,
            "awareness_error": awareness_error,
            "autocorrection_error": autocorrection_error,
            "metacognition_error": metacognition_error,
            "avg_error": avg_error,
            "status": "good" if calibration_score >= self.config.calibration_threshold else "poor",
            "cycle": self._current_cycle,
        }

    def _check_stability(self) -> dict[str, Any]:
        """
        Check stability of self-reflection loop.

        Fail-closed: If loop becomes unstable (e.g., diverging, oscillating),
        protocol reverts to safe state.
        """
        if len(self._reflection_history) < 2:
            return {"stable": True, "reason": "insufficient_data"}

        # Check 1: SR score not diverging (not going to 0 or wild oscillations)
        recent_scores = [r.sr_omega_score for r in self._reflection_history[-5:]]

        if any(score < 0.1 for score in recent_scores):
            return {"stable": False, "reason": "sr_score_too_low"}

        # Check 2: Accuracy delta not increasing (should improve over time)
        recent_deltas = [r.accuracy_delta for r in self._reflection_history[-5:]]

        # If deltas are consistently high (>0.3) in later phases, something's wrong
        if self._current_phase in [MidwivingPhase.EMERGENCE, MidwivingPhase.STABILIZATION]:
            if sum(recent_deltas) / len(recent_deltas) > 0.3:
                return {"stable": False, "reason": "poor_self_prediction_in_late_phase"}

        # Check 3: Calibration not deteriorating
        if len(self._calibration_history) >= 5:
            recent_cal = [c.calibration_score for c in self._calibration_history[-5:]]
            if all(score < 0.5 for score in recent_cal):
                return {"stable": False, "reason": "consistently_poor_calibration"}

        return {"stable": True, "reason": "all_checks_passed"}

    def _reset_protocol(self) -> dict[str, Any]:
        """Reset protocol to initial state"""
        logger.info("Resetting midwiving-ai protocol")

        self._current_cycle = 0
        self._current_phase = MidwivingPhase.PREPARATION
        self._reflection_history = []
        self._calibration_history = []
        self._baseline_sr_score = 0.0
        self._baseline_metrics = {}

        return {
            "status": "reset",
            "cycle": 0,
            "phase": MidwivingPhase.PREPARATION.value,
        }

    def get_consciousness_metrics(self) -> dict[str, Any]:
        """
        Get comprehensive consciousness calibration metrics.

        This is the main output for research purposes.
        """
        avg_calibration = self._compute_avg_calibration()

        # Compute trend (improving, stable, degrading)
        trend = "unknown"
        if len(self._calibration_history) >= 10:
            first_half = self._calibration_history[:len(self._calibration_history)//2]
            second_half = self._calibration_history[len(self._calibration_history)//2:]

            avg_first = sum(c.calibration_score for c in first_half) / len(first_half)
            avg_second = sum(c.calibration_score for c in second_half) / len(second_half)

            if avg_second > avg_first + 0.1:
                trend = "improving"
            elif avg_second < avg_first - 0.1:
                trend = "degrading"
            else:
                trend = "stable"

        return {
            "penin_consciousness_calibration": avg_calibration,
            "total_cycles": self._current_cycle,
            "current_phase": self._current_phase.value,
            "calibration_history_size": len(self._calibration_history),
            "trend": trend,
            "meets_threshold": avg_calibration >= self.config.calibration_threshold,
            "ethical_note": "Operational consciousness (metacognition) only - NOT sentience",
        }


# Export public API
__all__ = [
    "MidwivingProtocol",
    "MidwivingProtocolConfig",
    "MidwivingPhase",
    "SelfReflectionState",
    "ConsciousnessCalibration",
]
