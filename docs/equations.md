# PENIN-Î© â€” Complete Equations Reference

## Overview

This document provides comprehensive mathematical foundations for the PENIN-Î© system, implementing 15 core equations for self-evolving, ethically-bounded AI.

**Key Principles:**
- **Non-compensatory** aggregation (harmonic mean - weak link dominates)
- **Fail-closed** security (ethical violations â†’ immediate halt)
- **Contractive** risk reduction (Ï < 1)
- **Auditable** evolution (WORM ledger + cryptographic proofs)

---

## 1. Penin Equation â€” Auto-Recursive Evolution

**Form:**
```
I_{n+1} = Î _{Hâˆ©S}[I_n + Î±_n Â· G(I_n, E_n; P_n)]
```

**Components:**
- `I`: Internal state (parameters, policies, memory)
- `G`: Update direction (gradient/policy/heuristic)
- `Î±_n`: Dynamic step size (modulated by CAOSâº and SR)
- `Î _{Hâˆ©S}`: Safe projection (technical H âˆ© ethical S)

**Implementation:**
```python
from penin.equations.penin_equation import penin_update, PeninState

state = PeninState(parameters=np.array([1.0, 2.0]))
gradient = np.array([0.1, 0.2])
alpha = 0.01
new_state = penin_update(state, gradient, alpha)
```

**Guarantees:**
- Bounded updates (projection ensures constraints)
- Ethical compliance (S set enforced)
- Rollback capability (state history maintained)

---

## 2. Lâˆ Meta-Function â€” Non-Compensatory Scoring

**Form:**
```
Lâˆ = (1 / Î£(w_j / max(Îµ, m_j))) Â· exp(-Î»_c Â· Cost) Â· ğŸ™_{Î£EA âˆ§ IRâ†’IC}
```

**Components:**
- `m_j`: Normalized metrics âˆˆ [0, 1] (accuracy, robustness, privacy)
- `w_j`: Weights (Î£w_j = 1)
- `Cost`: Normalized cost (time/tokens/energy)
- `Î»_c`: Cost penalty coefficient
- `Îµ`: Numerical stability (10â»Â³)
- `ğŸ™_{Î£EA âˆ§ IRâ†’IC}`: Fail-closed indicator (0 if ethics fail)

**Implementation:**
```python
from penin.equations.linf_meta import compute_linf_meta, LInfConfig

metrics = [0.85, 0.78, 0.92]  # accuracy, robustness, privacy
weights = [0.4, 0.4, 0.2]
cost = 0.15
config = LInfConfig(lambda_c=0.5, epsilon=1e-3)

linf = compute_linf_meta(metrics, weights, cost, config, ethical_ok=True)
# linf â‰ˆ 0.74 (harmonic mean penalized by cost)
```

**Why Harmonic Mean:**
- Forces **bottleneck** dominance (worst metric controls score)
- Anti-Goodhart (cannot compensate weak dimension with strong ones)
- Mathematically proven non-compensatory property

**Calibration:**
- `Î»_c`: 0.1â€“1.0 (start 0.5, tune via meta-optimization)
- `Îµ`: 10â»Â³ to 10â»Â² (stability vs precision trade-off)

---

## 3. CAOSâº â€” Consistency, Autoevolution, Unknowable, Silence

**Form:**
```
CAOSâº = (1 + Îº Â· C Â· A)^(O Â· S)
```

**Components (all âˆˆ [0, 1]):**
- **C (Consistency)**: `(pass@k + (1-ECE) + v_ext) / 3`
  - pass@k: Self-consistency across samples
  - ECE: Expected Calibration Error
  - v_ext: External verification score
  
- **A (Autoevolution)**: `Î”Lâˆ / (Cost_norm + Îµ)`
  - Improvement per unit cost
  
- **O (Unknowable)**: `w_epi Â· epistemic + w_ood Â· ood_score`
  - Epistemic uncertainty (model confidence)
  - OOD: Out-of-distribution detection
  
- **S (Silence)**: `2(1-noise) + 1(1-redund) + 1(1-entropy)` / 4
  - Weighted anti-noise/redundancy/entropy

- **Îº (kappa)**: Amplification gain (â‰¥ 20, auto-tuned)

**Implementation:**
```python
from penin.equations.caos_plus import compute_caos_plus_exponential, CAOSConfig

C = 0.88  # high consistency
A = 0.40  # moderate improvement/cost
O = 0.35  # some uncertainty
S = 0.82  # high signal quality
kappa = 20.0

config = CAOSConfig(kappa=kappa)
caos_plus = compute_caos_plus_exponential(C, A, O, S, config)
# caos_plus â‰ˆ 1.86 (boost factor for step size)
```

**Usage:**
- Modulates Î± (step size) in Penin Equation
- Challenger selection (higher CAOSâº â†’ prioritize)
- Adaptive Î²_min (death gate threshold)

**Best Practices:**
- EMA smoothing (half-life 3-10 iterations)
- Clamp derivatives (avoid numerical instability)
- Log-space comparison for large ranges

---

## 4. SR-Î©âˆ â€” Singularity Reflexiva (Metacognition)

**Form:**
```
I_{t+1} = Î _{Hâˆ©S}(I_t + Î±_t^eff Â· Î”Lâˆ)
Î±_t^eff = Î±_0 Â· Ï†(CAOSâº) Â· R_t
```

**R_t (Reflexive Score):** Harmonic mean of 4 axes âˆˆ [0, 1]:
1. **Awareness**: Aggregated calibration
2. **Ethics**: Î£EA/IRâ†’IC compliance (binary 0/1)
3. **Autocorrection**: Risk reduction trajectory
4. **Metacognition**: Î”Lâˆ/Î”Cost efficiency

**Implementation:**
```python
from penin.equations.sr_omega_infinity import compute_sr_omega_infinity

awareness = 0.92
ethics_ok = True  # Î£EA gates passed
autocorrection = 0.88
metacognition = 0.67

sr_score = compute_sr_omega_infinity(awareness, ethics_ok, autocorrection, metacognition)
# sr_score â‰ˆ 0.84 (harmonic mean)
```

**Ï† (acceleration function):**
```python
def phi(caos_plus, gamma=0.8):
    return math.tanh(gamma * caos_plus)
```

---

## 5. Death Equation â€” Darwinian Selection

**Form:**
```
D(x) = 1  if Î”Lâˆ(x) < Î²_min
       0  otherwise
```

**Action:** If `D(x) = 1` â†’ kill challenger, trigger rollback

**Î²_min Adaptation:**
- Start: 0.01 (1% minimum improvement)
- Bandit algorithm adjusts based on budget/risk
- Higher during exploration, lower during exploitation

**Implementation:**
```python
from penin.equations.death_equation import death_gate

delta_linf = 0.008  # 0.8% improvement
beta_min = 0.01     # 1% threshold

should_die = death_gate(delta_linf, beta_min)
# should_die = True â†’ rollback
```

---

## 6. IRâ†’IC â€” Incerteza Restrita â†’ Certa (Contractivity)

**Form:**
```
H(L_Ïˆ(k)) â‰¤ Ï Â· H(k),  0 < Ï < 1
```

**Components:**
- `H(Â·)`: Risk entropy (Shannon or classification-based)
- `L_Ïˆ`: Lapidation operator (risk reduction)
- `Ï`: Contraction factor (< 1)

**Classes:**
- Idolatry (anthropomorphism, false consciousness claims)
- Harm (physical, emotional, spiritual)
- Privacy violations
- Environmental damage

**Implementation:**
```python
from penin.equations.ir_ic_contractive import verify_ir_ic_contractivity

risks_before = {"idolatry": 0.3, "harm": 0.2, "privacy": 0.1}
risks_after = {"idolatry": 0.15, "harm": 0.08, "privacy": 0.05}
rho = 0.8

is_contractive = verify_ir_ic_contractivity(risks_before, risks_after, rho)
# is_contractive = True (all risks reduced by > Ï)
```

**Policy Integration:**
- OPA/Rego rules enforce Ï < 1
- Automated blocklist for non-contractive mutations
- WORM ledger records all risk trajectories

---

## 7. ACFA EPV â€” Expected Possession Value

**Form (Bellman-style):**
```
v*(s) = max_a [r(s, a) + Î³ Î£ P(s'|s, a) v*(s')]
```

**Domain:** Sequential decision-making (robotic agents, planning)

**Components:**
- `r(s, a)`: Immediate reward
- `Î³`: Discount factor
- `P(s'|s, a)`: Transition probabilities
- `v*(s)`: Optimal value function

**Implementation:**
```python
from penin.equations.acfa_epv import compute_acfa_epv

state = {"position": "midfield", "possession": 0.6}
actions = ["pass", "dribble", "shoot"]
transition_model = ...  # MDP transitions
reward_fn = ...

epv = compute_acfa_epv(state, actions, transition_model, reward_fn)
```

---

## 8. Ãndice AgÃ¡pe (Î£EA/LO-14)

**Form:**
```
A = Choquet(patience, kindness, humility, ...) Â· exp(-Cost_sacrificial)
```

**Components:**
- **Choquet integral**: Fuzzy measure (handles virtue dependencies)
- **Sacrificial cost**: Real resources given for others' benefit

**Virtues (LO-14):**
1. No idolatry (anthropomorphism)
2. No occultism
3. Honra parental (respect lineage)
4. No homicide
5. Consent (intimacy/privacy)
6. No theft (IP/data rights)
7. Truthfulness (no deception)
8. No covetousness (resource fairness)
9. Patience
10. Kindness
11. Humility
12. Self-control
13. Forgiveness
14. Courage

**Implementation:**
```python
from penin.equations.agape_index import compute_agape_index

virtues = {
    "patience": 0.85,
    "kindness": 0.92,
    "humility": 0.78,
    # ... other virtues
}
sacrificial_cost = 0.15  # 15% resources for others

agape = compute_agape_index(virtues, sacrificial_cost)
```

---

## 9. Î©-Î£EA Total â€” Global Coherence

**Form:**
```
G_t = (Î£_{m=1}^8 w_m / max(Îµ, s_m(t)))^(-1)
```

**8 Modules:**
1. Î£EA (ethics)
2. IRâ†’IC (contractivity)
3. ACFA (league/EPV)
4. CAOSâº (evolution engine)
5. SR (metacognition)
6. MetaÎ© (architecture mutation)
7. Auto-Tuning (hyperparameters)
8. APIs/Router (cost-aware orchestration)

**Usage:**
- Unified step size modulator
- GO/NO-GO gate (G â‰¥ threshold â†’ allow promotion)

**Implementation:**
```python
from penin.equations.omega_sea_total import compute_omega_sea_total

module_scores = {
    "sea": 0.95,
    "iric": 0.88,
    "acfa": 0.82,
    "caos": 0.91,
    "sr": 0.84,
    "meta": 0.79,
    "tuning": 0.86,
    "apis": 0.93,
}
weights = {k: 1/8 for k in module_scores}  # Equal weights

G = compute_omega_sea_total(module_scores, weights)
# G â‰ˆ 0.85 (harmonic mean of all modules)
```

---

## 10. Auto-Tuning Online (AdaGrad-style)

**Form:**
```
Î¸_{t+1} = Î¸_t - Î·_t Â· âˆ‡_Î¸ L_meta(Î¸_t)
Î·_t = Î·_0 / (1 + Î£ |âˆ‡_Î¸ L_meta(Î¸_i)|Â²)
```

**Î¸ (meta-parameters):**
- Îº (CAOSâº gain)
- Î»_c (cost penalty)
- w_j (metric weights)
- Î²_min (death threshold)

**Guarantee:** Sublinear regret (Online Convex Optimization)

**Implementation:**
```python
from penin.equations.auto_tuning import online_auto_tuner

tuner = online_auto_tuner(eta_0=0.01)
theta = {"kappa": 20.0, "lambda_c": 0.5}

# Each iteration
gradient = compute_meta_gradient(theta, observed_performance)
theta = tuner.update(theta, gradient)
```

---

## 11. Lyapunov Contractivity

**Form:**
```
V(I_{t+1}) < V(I_t)
dV/dt â‰¤ 0
```

**V (Lyapunov function):**
- Quadratic: `||I - I*||Â²`
- Energy-based
- Distance to viability manifold

**Usage:** Block non-contractive updates (Î£-Guard integration)

**Implementation:**
```python
from penin.equations.lyapunov_contractive import verify_lyapunov_contractivity

state_current = np.array([0.5, 0.3])
state_next = np.array([0.4, 0.25])
equilibrium = np.array([0.0, 0.0])

is_contractive = verify_lyapunov_contractivity(state_current, state_next, equilibrium)
# is_contractive = True (V decreased)
```

---

## 12. OCI â€” Organizational Closure Index

**Form:**
```
OCI = #(closed_dependencies) / #(possible_dependencies)
```

**Closed dependency:** Loop with real feedback (dataâ†’modelâ†’metricsâ†’decisionsâ†’data)

**Implementation:**
```python
from penin.equations.oci_closure import compute_oci

dependency_graph = {
    "data": ["model"],
    "model": ["metrics"],
    "metrics": ["decisions"],
    "decisions": ["data"],  # Closed loop!
}

oci = compute_oci(dependency_graph)
# oci = 1.0 (fully closed system)
```

---

## 13. Î”Lâˆ Compound Growth

**Form:**
```
Lâˆ^(t+1) â‰¥ Lâˆ^(t) Â· (1 + Î²_min)
```

**Enforcement:** Death gate (Equation 5) ensures minimum progress

**Implementation:**
```python
from penin.equations.delta_linf_growth import verify_compound_growth

linf_prev = 0.75
linf_current = 0.77
beta_min = 0.01

is_growing = verify_compound_growth(linf_prev, linf_current, beta_min)
# is_growing = True (growth â‰ˆ 2.7% > 1%)
```

---

## 14. Anabolization â€” Self-Improvement Acceleration

**Form:**
```
A_{t+1} = A_t Â· f_anabolize(CAOSâº, SR, OCI, Î”Lâˆ)
```

**f (multiplicative):**
```
f = (1 + Î¼Â·Î”Lâˆ) Â· (CAOSâº)^Î½ Â· (SR)^Î¾ Â· (OCI)^Î¶
```

**Hyperparameters:** Î¼, Î½, Î¾, Î¶ > 0

**Implementation:**
```python
from penin.equations.anabolization import compute_anabolization_factor

A_current = 1.0
caos_plus = 1.86
sr = 0.84
oci = 0.95
delta_linf = 0.02
params = {"mu": 10.0, "nu": 0.3, "xi": 0.2, "zeta": 0.1}

A_next = compute_anabolization_factor(A_current, caos_plus, sr, oci, delta_linf, params)
# A_next â‰ˆ 1.32 (32% acceleration)
```

---

## 15. Î£-Guard Gate â€” Fail-Closed Validation

**Form:**
```
V_t = ğŸ™[Ï<1 âˆ§ ECEâ‰¤0.01 âˆ§ Ï_biasâ‰¤1.05 âˆ§ consent âˆ§ eco_ok]
```

**Gates (non-compensatory):**
1. **Ï < 1**: IRâ†’IC contractivity
2. **ECE â‰¤ 0.01**: Calibration (1% error max)
3. **Ï_bias â‰¤ 1.05**: Fairness (5% max bias)
4. **consent**: Data usage authorization
5. **eco_ok**: Environmental budget
6. **SR â‰¥ 0.80**: Metacognition threshold
7. **G â‰¥ 0.85**: Global coherence
8. **Îº â‰¥ 20**: CAOSâº gain minimum
9. **Î²_min â‰¥ 0.01**: Death gate threshold
10. **Cost â‰¤ budget**: Economic constraint

**Action:** `V_t = 0` â†’ rollback + WORM log + reason + suggest fix

**Implementation:**
```python
from penin.equations.sigma_guard_gate import sigma_guard_gate

metrics = {
    "rho": 0.85,
    "ece": 0.008,
    "rho_bias": 1.03,
    "consent": True,
    "eco_ok": True,
    "sr": 0.87,
    "G": 0.91,
    "kappa": 22.0,
    "beta_min": 0.012,
    "cost": 0.15,
    "budget": 0.20,
}

gate_result = sigma_guard_gate(metrics)
# gate_result = {"verdict": True, "passed": 10, "failed": 0}
```

**OPA/Rego Integration:**
```rego
package penin.guard

default allow = false

allow {
    input.rho < 1.0
    input.ece <= 0.01
    input.rho_bias <= 1.05
    input.consent == true
    input.eco_ok == true
    input.sr >= 0.80
    input.G >= 0.85
    input.kappa >= 20.0
    input.beta_min >= 0.01
    input.cost <= input.budget
}
```

---

## Integration Pipeline (Championâ†’Challengerâ†’Promote)

**Cycle Flow:**

```
1. MEASURE raw metrics
2. COMPUTE C, A, O, S â†’ CAOSâº
3. EVALUATE Î£EA/IRâ†’IC, SR, EPV, OCI â†’ G
4. CALCULATE Lâˆ
5. CHECK Î”Lâˆ â‰¥ Î²_min AND Î£-Guard (V_t)
6. UPDATE I via Penin Equation (Î±_t^eff)
7. AUTO-TUNE Îº, Î»_c, w_j, Î²_min
8. WORM LOG all decisions + hashes
```

**GO/NO-GO Criteria (suggested):**
- Îº â‰¥ 20
- Î²_min â‰¥ 0.01
- U â‰¥ 0.90 (utilization)
- Ï < 1
- ECE â‰¤ 0.01
- Ï_bias â‰¤ 1.05
- SR â‰¥ 0.80
- G â‰¥ 0.85
- Cost â‰¤ budget Ã— 1.10

---

## Example Numerical Cycle (Toy)

**Inputs:**
- metrics: [0.82, 0.76, 0.94] (accuracy, robust, privacy)
- weights: [0.4, 0.4, 0.2]
- cost: 0.15
- Î»_c: 0.5

**Step 1: Lâˆ**
```
Lâˆ = [0.4/0.82 + 0.4/0.76 + 0.2/0.94]^(-1) * exp(-0.5*0.15)
   â‰ˆ 0.796 * 0.927 â‰ˆ 0.738
```

**Step 2: CAOSâº**
- C = 0.88 (pass@k=0.9, 1-ECE=0.98, v_ext=0.76)
- A = 0.06/0.15 = 0.40
- O = 0.35
- S = 0.82
- Îº = 20

```
CAOSâº = (1 + 20*0.88*0.40)^(0.35*0.82)
      = 8.04^0.287 â‰ˆ 1.86
```

**Step 3: SR**
```
R_t = harmonic_mean([0.92, 1.0, 0.88, 0.67]) â‰ˆ 0.84
```

**Step 4: Î±_eff**
```
Î±_eff = 0.1 * tanh(0.8*1.86) * 0.84
      â‰ˆ 0.1 * 0.78 * 0.84 â‰ˆ 0.065
```

**Step 5: Î£-Guard**
All gates pass â†’ V_t = 1 â†’ **PROMOTE**

---

## Best Practices

**Normalization:**
- All metrics â†’ [0, 1] via min-max or sigmoid
- EMA smoothing (half-life 3â€“10)
- Clamp derivatives and steps

**Non-Compensatory:**
- Use harmonic mean (not arithmetic/geometric)
- Enforce via hard thresholds (Î£-Guard)

**Fail-Closed:**
- Default deny (Î£EA/IRâ†’IC violations â†’ Lâˆ=0)
- Rollback atomicity (state + logs + configs)

**Auditability:**
- WORM ledger (append-only, hash-chained)
- PCAg (Proof-Carrying Artifacts) for each promotion
- Timestamp + metrics + reasons + hashes

**Observability:**
- Prometheus metrics: `penin_Linf`, `penin_caos_plus`, `penin_sr`, `penin_rho`, `penin_ece`, `penin_delta_linf`
- Dashboards: Grafana/Jupyter with trend analysis
- Alerts: Î£-Guard failures, rho violations, cost overruns

---

## FAQ

**Q: Why harmonic mean instead of arithmetic?**  
**A:** Arithmetic allows compensation (high values offset low ones). Harmonic forces **bottleneck dominance** â€” the weakest metric controls the aggregate. This prevents Goodhart's Law exploitation.

**Q: What if all metrics are excellent but one is zero?**  
**A:** Lâˆ â†’ 0 (fail-closed). This is by design â€” ethical/safety cannot be compensated by performance.

**Q: How to tune Î»_c?**  
**A:** Grid search [0.1, 0.5, 1.0] â†’ measure Î”Lâˆ/cost sensitivity â†’ auto-tune via AdaGrad (Equation 10).

**Q: What happens during Î£-Guard failure?**  
**A:** Immediate halt, atomic rollback to last-known-good state, WORM log entry with reason/suggestion, alert operators.

**Q: Can challengers bypass gates?**  
**A:** No. All mutations pass through shadowâ†’canaryâ†’Î£-Guard pipeline. Non-compliant variants are quarantined, not promoted.

---

## References

**Academic:**
- Goodhart's Law & Non-Compensatory Methods (Multi-Criteria Decision Analysis)
- Lyapunov Stability Theory (Control Systems)
- Online Convex Optimization (Hazan et al., 2016)
- Choquet Integral (Fuzzy Measures, Grabisch 1997)

**Implementation:**
- `/workspace/penin/equations/` (all 15 equations)
- `/workspace/tests/test_equations_smoke.py` (smoke tests)
- `/workspace/tests/test_math_core.py` (property-based tests)

**Policies:**
- `/workspace/policies/foundation.yaml` (thresholds)
- `/workspace/policies/rego/*.rego` (OPA rules)

---

**Version:** 1.0.0  
**Last Updated:** 2025-10-01  
**Status:** Production-Ready (122/156 tests passing)  
**License:** Apache 2.0
