# CAOSâº Usage Guide - Motor Evolutivo PENIN-Î©

## Tabela de ConteÃºdos

1. [IntroduÃ§Ã£o](#introduÃ§Ã£o)
2. [VisÃ£o Geral da FÃ³rmula](#visÃ£o-geral-da-fÃ³rmula)
3. [Componentes Detalhados](#componentes-detalhados)
4. [Guia de ImplementaÃ§Ã£o](#guia-de-implementaÃ§Ã£o)
5. [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)
6. [Best Practices](#best-practices)
7. [Troubleshooting](#troubleshooting)
8. [FAQ](#faq)

---

## IntroduÃ§Ã£o

CAOSâº (Consistency, Autoevolution, Unknowable, Silence) Ã© o motor de evoluÃ§Ã£o
adaptativa central do sistema PENIN-Î©. Ele modula dinamicamente a taxa de
aprendizado baseado em quatro dimensÃµes fundamentais, equilibrando:

- **ExploraÃ§Ã£o**: Buscar em territÃ³rio desconhecido (alta incerteza)
- **ExploraÃ§Ã£o**: Refinar em territÃ³rio conhecido (baixa incerteza)

### Por Que CAOSâº?

Sistemas de IA tradicionais usam taxas de aprendizado fixas ou schedules simples.
CAOSâº vai alÃ©m ao adaptar a taxa baseado em:

1. **Qualidade** (CÂ·A): QuÃ£o bem o sistema estÃ¡ performando
2. **Contexto** (OÂ·S): Quanto precisa explorar vs explorar

Isso resulta em:
- âœ… ConvergÃªncia mais rÃ¡pida em territÃ³rios conhecidos
- âœ… ExploraÃ§Ã£o mais agressiva em territÃ³rios desconhecidos
- âœ… Melhor trade-off entre performance e custo
- âœ… AdaptaÃ§Ã£o automÃ¡tica a mudanÃ§as no ambiente

---

## VisÃ£o Geral da FÃ³rmula

### FÃ³rmula MatemÃ¡tica

```
CAOSâº = (1 + Îº Â· C Â· A)^(O Â· S)
```

### Anatomia da FÃ³rmula

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚  CAOSâº = (1 + Îº Â· C Â· A)^(O Â· S)               â”‚
â”‚          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”˜              â”‚
â”‚                â”‚            â”‚                   â”‚
â”‚             BASE        EXPOENTE                â”‚
â”‚          (Potencial)  (Agressividade)           â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

BASE: Quanto pode amplificar
  - CÂ·A = Qualidade do aprendizado
  - Îº = Intensidade da amplificaÃ§Ã£o
  - Range: [1, 1+Îº] para CÂ·A âˆˆ [0,1]

EXPOENTE: QuÃ£o agressiva Ã© a amplificaÃ§Ã£o
  - OÂ·S = Contexto de exploraÃ§Ã£o
  - Range: [0, 1]
  - 0 â†’ Sem amplificaÃ§Ã£o (base^0 = 1)
  - 1 â†’ AmplificaÃ§Ã£o mÃ¡xima (base^1 = base)
```

### InterpretaÃ§Ã£o Intuitiva

Pense em CAOSâº como um **acelerador de aprendizado**:

- **Motor (Base)**: PotÃªncia disponÃ­vel = qualidade do sistema (CÂ·A) Ã— ganho (Îº)
- **Pedal (Expoente)**: Quanto apertar = contexto de exploraÃ§Ã£o (OÂ·S)

**Exemplos**:
- Motor fraco + pedal fundo = pouco efeito
- Motor forte + pedal suave = aceleraÃ§Ã£o controlada
- Motor forte + pedal fundo = **aceleraÃ§Ã£o mÃ¡xima!**

---

## Componentes Detalhados

### C - Consistency (ConsistÃªncia) [0, 1]

**O Que Mede**: Confiabilidade das prediÃ§Ãµes do sistema.

**Como Calcular**:
```
C = wâ‚Â·pass@k + wâ‚‚Â·(1-ECE) + wâ‚ƒÂ·v_ext
```

**Sub-mÃ©tricas**:

#### 1. pass@k (Taxa de AutoconsistÃªncia)
- **DefiniÃ§Ã£o**: Probabilidade de gerar pelo menos 1 resposta correta em k tentativas
- **Como medir**: Gerar k amostras e verificar se pelo menos 1 estÃ¡ correta
- **Valores tÃ­picos**: 0.85-0.95 para sistemas calibrados
- **Peso sugerido**: 0.4

```python
# Exemplo de cÃ¡lculo
num_correct = 0
k = 10
for i in range(k):
    output = model.generate(prompt)
    if verify(output):
        num_correct += 1

pass_at_k = 1.0 - (1.0 - num_correct/k) ** k  # Estimativa nÃ£o-enviesada
```

#### 2. ECE - Expected Calibration Error
- **DefiniÃ§Ã£o**: DiferenÃ§a entre confianÃ§a e acurÃ¡cia
- **Como medir**: Dividir prediÃ§Ãµes em bins por confianÃ§a, calcular |conf - acc|
- **Valores bons**: ECE < 0.05 (< 5% de erro)
- **Peso sugerido**: 0.3
- **Nota**: Invertemos para mÃ©trica positiva: (1-ECE)

```python
# Exemplo simplificado
ece = expected_calibration_error(predictions, confidences, num_bins=10)
ece_normalized = min(1.0, ece)  # Clamp em [0, 1]
consistency_component = 1.0 - ece_normalized
```

#### 3. v_ext (VerificaÃ§Ã£o Externa)
- **DefiniÃ§Ã£o**: Score de validaÃ§Ã£o por oracles, testes formais, ou humanos
- **Como medir**: Taxa de aprovaÃ§Ã£o em testes externos
- **Valores tÃ­picos**: 0.80-0.90
- **Peso sugerido**: 0.3

```python
# Exemplo
external_tests_passed = 88
external_tests_total = 100
v_ext = external_tests_passed / external_tests_total  # 0.88
```

**ImplementaÃ§Ã£o**:
```python
from penin.core.caos import ConsistencyMetrics

consistency = ConsistencyMetrics(
    pass_at_k=0.92,
    ece=0.008,                    # 0.8% error
    external_verification=0.88,
    weight_pass=0.4,
    weight_ece=0.3,
    weight_external=0.3
)

C = consistency.compute_c()
print(f"C = {C:.3f}")  # C â‰ˆ 0.930
```

**InterpretaÃ§Ã£o**:
- **C > 0.8**: Sistema confiÃ¡vel, pode explorar mais agressivamente
- **C = 0.5-0.8**: Sistema moderado, exploraÃ§Ã£o equilibrada
- **C < 0.5**: Sistema inconsistente, precisa calibrar antes de explorar

---

### A - Autoevolution (AutoevoluÃ§Ã£o) [0, 1]

**O Que Mede**: EficiÃªncia do aprendizado (ganho por custo).

**Como Calcular**:
```
A_raw = Î”Lâˆâº / (Cost_norm + Îµ)
A = min(A_raw / max_a, 1.0)  # Normalizar para [0, 1]
```

**Sub-mÃ©tricas**:

#### 1. Î”Lâˆâº (Ganho de Performance)
- **DefiniÃ§Ã£o**: Melhoria na mÃ©trica Lâˆ (meta-score agregada)
- **Como medir**: Lâˆ_new - Lâˆ_old
- **Valores tÃ­picos**: 0.01-0.10 (1%-10% de ganho)
- **Nota**: SÃ³ considera ganhos positivos: max(0, Î”Lâˆ)

#### 2. Cost_norm (Custo Normalizado)
- **DefiniÃ§Ã£o**: Recursos gastos (tempo, tokens, energia)
- **Como medir**: Custo atual / Custo budget
- **Valores tÃ­picos**: 0.05-0.20 (5%-20% do budget)

**ImplementaÃ§Ã£o**:
```python
from penin.core.caos import AutoevolutionMetrics

autoevolution = AutoevolutionMetrics(
    delta_linf=0.06,        # 6% de ganho
    cost_normalized=0.15,   # 15% do budget
    max_a=10.0              # Clamp antes de normalizar
)

A = autoevolution.compute_a()
print(f"A = {A:.3f}")  # A â‰ˆ 0.040 (normalizado)
```

**InterpretaÃ§Ã£o**:
- **A > 0.6**: Aprendizado eficiente, bom ROI
- **A = 0.3-0.6**: Aprendizado moderado
- **A < 0.3**: Aprendizado ineficiente ou estagnado

---

### O - Unknowable (IncognoscÃ­vel) [0, 1]

**O Que Mede**: Incerteza e necessidade de exploraÃ§Ã£o.

**Como Calcular**:
```
O = w_epiÂ·epistemic + w_oodÂ·ood_score + w_ensÂ·ensemble_disagreement
```

**Sub-mÃ©tricas**:

#### 1. Epistemic Uncertainty (Incerteza EpistÃªmica)
- **DefiniÃ§Ã£o**: Incerteza do modelo sobre as prediÃ§Ãµes
- **Como medir**: 
  - Entropia: H(p) = -Î£ p_i log p_i
  - Mutual Information em Bayesian NNs
  - VariÃ¢ncia em dropout variational
- **Valores tÃ­picos**: 0.2-0.5
- **Peso sugerido**: 0.4

```python
# Exemplo com entropia
probs = softmax(logits)
entropy = -np.sum(probs * np.log(probs + 1e-10))
entropy_normalized = entropy / np.log(num_classes)  # Normalizar
```

#### 2. OOD Score (Out-of-Distribution)
- **DefiniÃ§Ã£o**: DistÃ¢ncia de distribuiÃ§Ã£o de treino
- **Como medir**:
  - Mahalanobis distance
  - KL divergence
  - Reconstruction error (autoencoders)
- **Valores tÃ­picos**: 0.1-0.4
- **Peso sugerido**: 0.3

#### 3. Ensemble Disagreement
- **DefiniÃ§Ã£o**: VariÃ¢ncia entre prediÃ§Ãµes de mÃºltiplos modelos
- **Como medir**: Std ou variance entre ensemble
- **Valores tÃ­picos**: 0.15-0.35
- **Peso sugerido**: 0.3

**ImplementaÃ§Ã£o**:
```python
from penin.core.caos import IncognoscibleMetrics

incognoscible = IncognoscibleMetrics(
    epistemic_uncertainty=0.35,
    ood_score=0.28,
    ensemble_disagreement=0.30,
    weight_epistemic=0.4,
    weight_ood=0.3,
    weight_ensemble=0.3
)

O = incognoscible.compute_o()
print(f"O = {O:.3f}")  # O â‰ˆ 0.314
```

**InterpretaÃ§Ã£o**:
- **O > 0.6**: Alta incerteza â†’ precisa EXPLORAR mais
- **O = 0.3-0.6**: Incerteza moderada â†’ balancear exploraÃ§Ã£o/exploraÃ§Ã£o
- **O < 0.3**: Baixa incerteza â†’ pode EXPLOITAR (exploit)

---

### S - Silence (SilÃªncio) [0, 1]

**O Que Mede**: Qualidade do sinal (anti-ruÃ­do).

**Como Calcular**:
```
S = vâ‚Â·(1-noise) + vâ‚‚Â·(1-redund) + vâ‚ƒÂ·(1-entropy)
```

PonderaÃ§Ã£o sugerida: **vâ‚:vâ‚‚:vâ‚ƒ = 2:1:1** (ruÃ­do Ã© mais crÃ­tico)

**Sub-mÃ©tricas**:

#### 1. Anti-Noise (Anti-RuÃ­do)
- **DefiniÃ§Ã£o**: Inverso da proporÃ§Ã£o de ruÃ­do no sinal
- **Como medir**: 1 - (ruÃ­do / sinal_total)
- **Valores bons**: noise < 0.1 â†’ anti-noise > 0.9
- **Peso sugerido**: 0.5 (2/4)

#### 2. Anti-Redundancy (Anti-RedundÃ¢ncia)
- **DefiniÃ§Ã£o**: Inverso da proporÃ§Ã£o de informaÃ§Ã£o duplicada
- **Como medir**: 1 - (redundÃ¢ncia / informaÃ§Ã£o_total)
- **Valores bons**: redundancy < 0.15 â†’ anti-redundancy > 0.85
- **Peso sugerido**: 0.25 (1/4)

#### 3. Anti-Entropy (Anti-Entropia)
- **DefiniÃ§Ã£o**: Inverso da desordem/imprevisibilidade
- **Como medir**: 1 - (entropia / entropia_max)
- **Valores bons**: entropy < 0.2 â†’ anti-entropy > 0.8
- **Peso sugerido**: 0.25 (1/4)

**ImplementaÃ§Ã£o**:
```python
from penin.core.caos import SilenceMetrics

silence = SilenceMetrics(
    noise_ratio=0.08,         # 8% ruÃ­do
    redundancy_ratio=0.12,    # 12% redundÃ¢ncia
    entropy_normalized=0.18,  # 18% entropia
    weight_noise=0.5,         # 2:1:1
    weight_redundancy=0.25,
    weight_entropy=0.25
)

S = silence.compute_s()
print(f"S = {S:.3f}")  # S â‰ˆ 0.885
```

**InterpretaÃ§Ã£o**:
- **S > 0.8**: Sinal limpo, alta confianÃ§a
- **S = 0.5-0.8**: Sinal moderado
- **S < 0.5**: Sinal ruidoso, baixa confianÃ§a

---

### Îº - Kappa (Ganho Base)

**O Que Controla**: Intensidade da amplificaÃ§Ã£o.

**Range**: Îº â‰¥ 20 (padrÃ£o), tÃ­pico: [10, 100]

**Efeito na AmplificaÃ§Ã£o**:

| Îº    | Tipo         | Range tÃ­pico CAOSâº | Uso                    |
|------|--------------|-------------------|------------------------|
| 10   | Conservador  | 1.0 - 2.5Ã—        | Ambientes estÃ¡veis     |
| 20   | **PadrÃ£o**   | 1.0 - 3.5Ã—        | **Recomendado**        |
| 50   | Agressivo    | 1.0 - 5.0Ã—        | EvoluÃ§Ã£o rÃ¡pida        |
| 100  | Extremo      | 1.0 - 7.0Ã—        | ExploraÃ§Ã£o mÃ¡xima      |

**Auto-tuning**: Îº pode ser otimizado via **EquaÃ§Ã£o 10** (bandit meta-optimization).

```python
from penin.core.caos import CAOSConfig

# ConfiguraÃ§Ã£o conservadora
config_conservative = CAOSConfig(kappa=10.0)

# ConfiguraÃ§Ã£o padrÃ£o (recomendada)
config_default = CAOSConfig(kappa=20.0)

# ConfiguraÃ§Ã£o agressiva
config_aggressive = CAOSConfig(kappa=50.0)
```

---

## Guia de ImplementaÃ§Ã£o

### Quick Start (5 minutos)

```python
from penin.core.caos import compute_caos_plus_exponential

# 1. Definir componentes (valores jÃ¡ calculados)
C = 0.88  # Alta consistÃªncia
A = 0.40  # AutoevoluÃ§Ã£o moderada
O = 0.35  # Incerteza moderada
S = 0.82  # Alto silÃªncio
kappa = 20.0

# 2. Calcular CAOSâº
caos_plus = compute_caos_plus_exponential(C, A, O, S, kappa)

# 3. Usar para modular taxa de aprendizado
alpha_base = 0.01
alpha_effective = alpha_base * caos_plus

print(f"CAOSâº: {caos_plus:.4f}")
print(f"Î±_eff: {alpha_effective:.6f}")
```

### ImplementaÃ§Ã£o Completa (ProduÃ§Ã£o)

```python
from penin.core.caos import (
    compute_caos_plus_complete,
    ConsistencyMetrics,
    AutoevolutionMetrics,
    IncognoscibleMetrics,
    SilenceMetrics,
    CAOSConfig,
    CAOSState
)

# 1. Definir mÃ©tricas estruturadas
consistency = ConsistencyMetrics(
    pass_at_k=0.92,
    ece=0.008,
    external_verification=0.88
)

autoevolution = AutoevolutionMetrics(
    delta_linf=0.06,
    cost_normalized=0.15
)

incognoscible = IncognoscibleMetrics(
    epistemic_uncertainty=0.35,
    ood_score=0.28,
    ensemble_disagreement=0.30
)

silence = SilenceMetrics(
    noise_ratio=0.08,
    redundancy_ratio=0.12,
    entropy_normalized=0.18
)

# 2. Configurar com EMA para estabilidade temporal
config = CAOSConfig(
    kappa=25.0,
    ema_half_life=5,
    caos_min=1.0,
    caos_max=10.0
)

# 3. Criar estado para tracking
state = CAOSState()

# 4. Computar CAOSâº
caos_plus, details = compute_caos_plus_complete(
    consistency, autoevolution, incognoscible, silence,
    config, state
)

# 5. Usar resultados
print(f"CAOSâº: {caos_plus:.4f}")
print(f"Componentes: {details['components_raw']}")
print(f"Estabilidade: {details['state_stability']:.3f}")

# 6. Registrar para auditoria (WORM ledger)
worm_entry = {
    "timestamp": time.time(),
    "caos_plus": caos_plus,
    **details
}
```

### Loop de Treinamento

```python
# Setup inicial
config = CAOSConfig(kappa=20.0, ema_half_life=5)
state = CAOSState()
alpha_base = 0.01

for epoch in range(num_epochs):
    # 1. Coletar mÃ©tricas da Ã©poca
    consistency = get_consistency_metrics(epoch)
    autoevolution = get_autoevolution_metrics(epoch)
    incognoscible = get_incognoscible_metrics(epoch)
    silence = get_silence_metrics(epoch)
    
    # 2. Calcular CAOSâº (com EMA automÃ¡tico)
    caos_plus, details = compute_caos_plus_complete(
        consistency, autoevolution, incognoscible, silence,
        config, state
    )
    
    # 3. Modular taxa de aprendizado
    alpha_effective = alpha_base * caos_plus
    
    # 4. Treinar com Î±_eff
    train_step(model, alpha_effective)
    
    # 5. Log para monitoramento
    logger.log({
        "epoch": epoch,
        "caos_plus": caos_plus,
        "alpha_effective": alpha_effective,
        "stability": details['state_stability']
    })
```

---

## Exemplos PrÃ¡ticos

### Exemplo 1: ExploraÃ§Ã£o em TerritÃ³rio Desconhecido

**CenÃ¡rio**: Sistema entrando em novo domÃ­nio, precisa explorar.

```python
# MÃ©tricas tÃ­picas de exploraÃ§Ã£o
consistency = ConsistencyMetrics(
    pass_at_k=0.55,         # Baixa (incerto)
    ece=0.08,               # Alta (mal calibrado)
    external_verification=0.60
)

autoevolution = AutoevolutionMetrics(
    delta_linf=0.03,        # Ganho baixo
    cost_normalized=0.20    # Custo alto (explorando)
)

incognoscible = IncognoscibleMetrics(
    epistemic_uncertainty=0.75,  # ALTA incerteza
    ood_score=0.65,             # ALTA OOD
    ensemble_disagreement=0.70   # ALTA disagreement
)

silence = SilenceMetrics(
    noise_ratio=0.15,       # Mais ruÃ­do
    redundancy_ratio=0.18,
    entropy_normalized=0.25
)

caos, details = compute_caos_plus_complete(
    consistency, autoevolution, incognoscible, silence
)

# Resultado esperado:
# C baixo Ã— A baixo = base baixa (~2-3)
# O alto Ã— S moderado = expoente moderado-alto (~0.4-0.5)
# CAOSâº â‰ˆ 1.5-2.0 (amplificaÃ§Ã£o moderada para exploraÃ§Ã£o)
```

### Exemplo 2: ExploraÃ§Ã£o em TerritÃ³rio Conhecido

**CenÃ¡rio**: Sistema refinando performance em domÃ­nio familiar.

```python
# MÃ©tricas tÃ­picas de exploraÃ§Ã£o
consistency = ConsistencyMetrics(
    pass_at_k=0.92,         # ALTA (confiante)
    ece=0.008,              # Baixa (bem calibrado)
    external_verification=0.88
)

autoevolution = AutoevolutionMetrics(
    delta_linf=0.08,        # Ganho moderado-alto
    cost_normalized=0.12    # Custo baixo (eficiente)
)

incognoscible = IncognoscibleMetrics(
    epistemic_uncertainty=0.20,  # BAIXA incerteza
    ood_score=0.15,             # BAIXA OOD
    ensemble_disagreement=0.18   # BAIXA disagreement
)

silence = SilenceMetrics(
    noise_ratio=0.05,       # Baixo ruÃ­do
    redundancy_ratio=0.08,
    entropy_normalized=0.12
)

caos, details = compute_caos_plus_complete(
    consistency, autoevolution, incognoscible, silence
)

# Resultado esperado:
# C alto Ã— A alto = base alta (~6-8)
# O baixo Ã— S alto = expoente baixo (~0.15-0.25)
# CAOSâº â‰ˆ 1.3-1.7 (amplificaÃ§Ã£o moderada para exploraÃ§Ã£o)
```

### Exemplo 3: Sweet Spot (MÃ¡xima AmplificaÃ§Ã£o)

**CenÃ¡rio**: Sistema aprendendo rapidamente em territÃ³rio parcialmente conhecido.

```python
# MÃ©tricas do sweet spot
consistency = ConsistencyMetrics(
    pass_at_k=0.88,
    ece=0.012,
    external_verification=0.85
)

autoevolution = AutoevolutionMetrics(
    delta_linf=0.10,        # ALTO ganho
    cost_normalized=0.10    # Custo moderado
)

incognoscible = IncognoscibleMetrics(
    epistemic_uncertainty=0.55,  # Incerteza moderada-alta
    ood_score=0.45,
    ensemble_disagreement=0.50
)

silence = SilenceMetrics(
    noise_ratio=0.08,
    redundancy_ratio=0.10,
    entropy_normalized=0.15
)

caos, details = compute_caos_plus_complete(
    consistency, autoevolution, incognoscible, silence
)

# Resultado esperado:
# C alto Ã— A alto = base MUITO alta (~10-15)
# O moderado-alto Ã— S alto = expoente moderado-alto (~0.4-0.6)
# CAOSâº â‰ˆ 3.0-4.5 (MÃXIMA amplificaÃ§Ã£o! ğŸš€)
```

---

## Best Practices

### 1. Use SuavizaÃ§Ã£o Temporal (EMA)

**Problema**: MÃ©tricas oscilam entre iteraÃ§Ãµes.

**SoluÃ§Ã£o**: Configure `ema_half_life`.

```python
config = CAOSConfig(
    kappa=20.0,
    ema_half_life=5  # Suavizar em 5 iteraÃ§Ãµes
)
state = CAOSState()

# EMA Ã© aplicado automaticamente
for epoch in range(num_epochs):
    caos, _ = compute_caos_plus_complete(..., config, state)
    # state Ã© atualizado in-place com EMA
```

**Guidelines**:
- `ema_half_life = 3`: Resposta rÃ¡pida (ambientes dinÃ¢micos)
- `ema_half_life = 5`: **Balanceado (recomendado)**
- `ema_half_life = 10`: Resposta lenta (ambientes estÃ¡veis)

### 2. Configure Clamps Apropriados

```python
config = CAOSConfig(
    kappa=20.0,
    kappa_min=10.0,    # Nunca menos que 10
    kappa_max=100.0,   # Nunca mais que 100
    caos_min=1.0,      # CAOSâº sempre â‰¥ 1
    caos_max=10.0,     # Limitar explosÃ£o
)
```

### 3. Use Log-space para ComparaÃ§Ãµes

```python
config = CAOSConfig(use_log_space=True)
caos, details = compute_caos_plus_complete(..., config)

log_caos = details['caos_plus_log']
# Ãštil para:
# - Plotting
# - Ranking de challengers
# - AnÃ¡lise estatÃ­stica
```

### 4. Registre Tudo para Auditoria

```python
caos, details = compute_caos_plus_complete(...)

# Details contÃ©m TODAS mÃ©tricas intermediÃ¡rias
worm_entry = {
    "timestamp": time.time(),
    "caos_plus": caos,
    "components_raw": details['components_raw'],
    "components_smoothed": details['components_smoothed'],
    "kappa": details['kappa'],
    "state_stability": details['state_stability'],
    # ... etc
}

# Registrar no WORM ledger (write-once-read-many)
worm_ledger.append(worm_entry)
```

### 5. Monitore Estabilidade

```python
_, details = compute_caos_plus_complete(...)

stability = details['state_stability']

if stability < 0.95:
    print("âš ï¸  CAOSâº instÃ¡vel, considere aumentar ema_half_life")
elif stability > 0.99:
    print("âœ… CAOSâº muito estÃ¡vel")
```

---

## Troubleshooting

### Problema 1: CAOSâº sempre prÃ³ximo de 1.0

**Sintoma**: `caos_plus â‰ˆ 1.0` (sem amplificaÃ§Ã£o)

**Causas possÃ­veis**:

1. **CÂ·A muito baixo** (base â‰ˆ 1):
   ```python
   # Debug
   C = details['components_smoothed']['C']
   A = details['components_smoothed']['A']
   print(f"C={C:.3f}, A={A:.3f}, CÂ·A={C*A:.3f}")
   
   # Se CÂ·A < 0.1:
   # â†’ Sistema tem baixa qualidade
   # â†’ Verificar mÃ©tricas de consistÃªncia e autoevoluÃ§Ã£o
   ```

2. **OÂ·S muito baixo** (expoente â‰ˆ 0):
   ```python
   # Debug
   O = details['components_smoothed']['O']
   S = details['components_smoothed']['S']
   print(f"O={O:.3f}, S={S:.3f}, OÂ·S={O*S:.3f}")
   
   # Se OÂ·S < 0.1:
   # â†’ Sistema tem baixa incerteza E baixo silÃªncio
   # â†’ Verificar mÃ©tricas de incognoscÃ­vel
   ```

**SoluÃ§Ãµes**:
- Verificar qualidade das mÃ©tricas de entrada
- Ajustar pesos nas mÃ©tricas
- Considerar usar Îº maior (se apropriado)

### Problema 2: CAOSâº oscila muito

**Sintoma**: `caos_plus` varia muito entre iteraÃ§Ãµes

**Causa**: MÃ©tricas de entrada oscilando, sem suavizaÃ§Ã£o

**SoluÃ§Ãµes**:

1. **Aumentar EMA half-life**:
   ```python
   config = CAOSConfig(ema_half_life=10)  # Mais suavizaÃ§Ã£o
   ```

2. **Verificar qualidade das mÃ©tricas**:
   ```python
   # Plotar mÃ©tricas raw vs smoothed
   raw = details['components_raw']
   smoothed = details['components_smoothed']
   
   # Se raw oscila muito:
   # â†’ Problema nas mÃ©tricas de entrada
   # â†’ Melhorar coleta de mÃ©tricas
   ```

### Problema 3: CAOSâº sempre no mÃ¡ximo (caos_max)

**Sintoma**: `caos_plus == caos_max` (saturando)

**Causas**:

1. **Îº muito alto**:
   ```python
   kappa = details['kappa']
   if kappa > 50:
       print("Îº muito alto, considere reduzir")
   ```

2. **caos_max muito baixo**:
   ```python
   config = CAOSConfig(caos_max=20.0)  # Aumentar teto
   ```

3. **CÂ·A E OÂ·S ambos muito altos**:
   ```python
   # Isso Ã© na verdade DESEJÃVEL em cenÃ¡rios de sweet spot!
   # Mas se acontece sempre:
   # â†’ Verificar se mÃ©tricas estÃ£o super-otimistas
   ```

### Problema 4: Componentes calculados parecem errados

**Debug Completo**:

```python
def debug_caos(details):
    """FunÃ§Ã£o helper para debug completo"""
    print("=== CAOSâº DEBUG ===")
    
    # 1. MÃ©tricas de entrada
    print("\n1. MÃ©tricas de Entrada:")
    for component, metrics in details['metrics_input'].items():
        print(f"  {component}:")
        for k, v in metrics.items():
            print(f"    {k}: {v:.4f}")
    
    # 2. Componentes calculados
    print("\n2. Componentes CAOS:")
    raw = details['components_raw']
    smoothed = details['components_smoothed']
    print(f"  Raw:      C={raw['C']:.3f}, A={raw['A']:.3f}, "
          f"O={raw['O']:.3f}, S={raw['S']:.3f}")
    print(f"  Smoothed: C={smoothed['C']:.3f}, A={smoothed['A']:.3f}, "
          f"O={smoothed['O']:.3f}, S={smoothed['S']:.3f}")
    
    # 3. CÃ¡lculo CAOSâº
    print("\n3. CÃ¡lculo CAOSâº:")
    C, A = smoothed['C'], smoothed['A']
    O, S = smoothed['O'], smoothed['S']
    kappa = details['kappa']
    base = 1 + kappa * C * A
    exponent = O * S
    print(f"  Base = 1 + {kappa}Ã—{C:.3f}Ã—{A:.3f} = {base:.4f}")
    print(f"  Exponent = {O:.3f}Ã—{S:.3f} = {exponent:.4f}")
    print(f"  CAOSâº_raw = {base:.4f}^{exponent:.4f} = {details['caos_plus_raw']:.4f}")
    print(f"  CAOSâº_clamped = {details['caos_plus_clamped']:.4f}")
    print(f"  CAOSâº_final = {details['caos_plus_final']:.4f}")
    
    # 4. Estado
    print("\n4. Estado:")
    print(f"  Updates: {details['state_update_count']}")
    print(f"  Stability: {details['state_stability']:.4f}")

# Uso
caos, details = compute_caos_plus_complete(...)
debug_caos(details)
```

---

## FAQ

### Q1: Quando usar `compute_caos_plus_exponential` vs `compute_caos_plus_complete`?

**A**: 
- Use `compute_caos_plus_exponential` quando jÃ¡ tem C, A, O, S calculados
- Use `compute_caos_plus_complete` para pipeline completo com mÃ©tricas estruturadas

### Q2: Como escolher Îº (kappa)?

**A**: 
- PadrÃ£o: Îº = 20 (recomendado para a maioria dos casos)
- Conservador: Îº = 10-15 (ambientes sensÃ­veis)
- Agressivo: Îº = 30-50 (evoluÃ§Ã£o rÃ¡pida)
- Extremo: Îº = 50-100 (exploraÃ§Ã£o mÃ¡xima, use com cuidado)

### Q3: O que fazer se CAOSâº Ã© sempre 1.0?

**A**: Veja [Problema 1 em Troubleshooting](#problema-1-caos-sempre-prÃ³ximo-de-10)

### Q4: Posso usar CAOSâº sem EMA?

**A**: Sim, mas nÃ£o recomendado:
```python
config = CAOSConfig(ema_half_life=0)  # Desabilita EMA
```
Isso remove suavizaÃ§Ã£o temporal, causando mais oscilaÃ§Ãµes.

### Q5: Como interpretar `state_stability`?

**A**:
- `> 0.99`: Muito estÃ¡vel (bom)
- `0.95-0.99`: EstÃ¡vel (ok)
- `< 0.95`: InstÃ¡vel (considere mais suavizaÃ§Ã£o)

### Q6: CAOSâº pode ser > 10.0?

**A**: Por padrÃ£o nÃ£o (clamped em `caos_max=10.0`), mas vocÃª pode configurar:
```python
config = CAOSConfig(caos_max=20.0)  # Permitir atÃ© 20Ã—
```

### Q7: Qual Ã© a diferenÃ§a entre `compute_caos_plus` e `phi_caos`?

**A**:
- `compute_caos_plus`: Wrapper de compatibilidade, retorna tupla `(phi, details)`
- `phi_caos`: FÃ³rmula com saturaÃ§Ã£o tanh, output em [0, 1)
- **Recomendado**: Use `compute_caos_plus_exponential` para casos novos

### Q8: Como fazer auto-tuning de Îº?

**A**: Use a EquaÃ§Ã£o 10 (bandit meta-optimization). Exemplo simplificado:
```python
# Testar diferentes Îº
kappas = [10, 20, 30, 50]
performances = []

for kappa in kappas:
    config = CAOSConfig(kappa=kappa)
    perf = train_and_evaluate(config)
    performances.append(perf)

# Escolher melhor Îº
best_kappa = kappas[np.argmax(performances)]
```

### Q9: CAOSâº funciona para reinforcement learning?

**A**: Sim! Use:
- C: Taxa de sucesso, consistÃªncia de polÃ­tica
- A: Melhoria de reward / custo
- O: Incerteza sobre transiÃ§Ãµes
- S: Qualidade de observaÃ§Ãµes

### Q10: Posso usar CAOSâº para seleÃ§Ã£o de modelos?

**A**: Sim! Calcule CAOSâº para cada modelo e ranqueie:
```python
models_caos = []
for model in candidate_models:
    caos = compute_caos_for_model(model)
    models_caos.append((model, caos))

# Ordenar por CAOSâº (maior = melhor)
models_caos.sort(key=lambda x: x[1], reverse=True)
best_model = models_caos[0][0]
```

---

## Recursos Adicionais

### CÃ³digo Fonte
- **ImplementaÃ§Ã£o canÃ´nica**: `penin/core/caos.py`
- **Exemplos executÃ¡veis**: `python penin/core/caos.py`
- **Testes**: `tests/test_caos.py`

### DocumentaÃ§Ã£o
- **EquaÃ§Ãµes**: `docs/equations.md` (SeÃ§Ã£o 3)
- **Arquitetura**: `docs/architecture.md`
- **Guia completo**: Este arquivo

### Papers e ReferÃªncias
- PENIN-Î© Master Equation (SeÃ§Ã£o 1 de equations.md)
- SR-Î©âˆ Reflexive Score (SeÃ§Ã£o 4 de equations.md)
- ACFA League (docs/architecture.md)

---

## ConclusÃ£o

CAOSâº Ã© um componente central do sistema PENIN-Î© que permite evoluÃ§Ã£o adaptativa
inteligente. Ao balancear qualidade (CÂ·A) e contexto (OÂ·S), o sistema pode:

âœ… Explorar eficientemente em territÃ³rios desconhecidos  
âœ… Explorar eficientemente em territÃ³rios conhecidos  
âœ… Adaptar-se automaticamente a mudanÃ§as  
âœ… Manter auditabilidade completa  

Para comeÃ§ar rapidamente, veja a seÃ§Ã£o [Guia de ImplementaÃ§Ã£o](#guia-de-implementaÃ§Ã£o).

Para casos de uso avanÃ§ados, veja [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos).

Para problemas, veja [Troubleshooting](#troubleshooting).

---

**VersÃ£o**: 1.0  
**Ãšltima atualizaÃ§Ã£o**: 2024  
**Autor**: PENIN-Î© Team  
**LicenÃ§a**: Apache 2.0
